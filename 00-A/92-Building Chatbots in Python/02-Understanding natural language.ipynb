{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'goodbye': re.compile('bye|farewell'), 'greet': re.compile('hello|hi|hey'), 'thankyou': re.compile('thank|thx')}\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary of patterns\n",
    "import re\n",
    "\n",
    "patterns = {}\n",
    "keywords ={'goodbye': ['bye', 'farewell'],\n",
    " 'greet': ['hello', 'hi', 'hey'],\n",
    " 'thankyou': ['thank', 'thx']}\n",
    "# Iterate over the keywords dictionary\n",
    "for intent, keys in keywords.items():\n",
    "    # Create regular expressions and compile them into pattern objects\n",
    "    patterns[intent] = re.compile('|'.join(keys))\n",
    "\n",
    "# Print the patterns\n",
    "print(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(message):\n",
    "    # Print user_template including the user_message\n",
    "    print(user_template.format(message))\n",
    "    # Get the bot's response to the message\n",
    "    response = respond(message)\n",
    "    # Print the bot template including the bot's response.\n",
    "    print(bot_template.format(response))\n",
    "# Create templates\n",
    "bot_template = \"BOT : {0}\"\n",
    "user_template = \"USER : {0}\"\n",
    "# Define respond()\n",
    "rules = {'I want (.*)': ['What would it mean if you got {0}',\n",
    "  'Why do you want {0}',\n",
    "  \"What's stopping you from getting {0}\"],\n",
    " 'do you remember (.*)': ['Did you think I would forget {0}',\n",
    "  \"Why haven't you been able to forget {0}\",\n",
    "  'What about {0}',\n",
    "  'Yes .. and?'],\n",
    " 'do you think (.*)': ['if {0}? Absolutely.', 'No chance'],\n",
    " 'if (.*)': [\"Do you really think it's likely that {0}\",\n",
    "  'Do you wish that {0}',\n",
    "  'What do you think about {0}',\n",
    "  'Really--if {0}']}\n",
    "# Define replace_pronouns()\n",
    "import re\n",
    "\n",
    "def replace_pronouns(message):\n",
    "    message = message.lower()\n",
    "    if 'me' in message:\n",
    "        # Replace 'me' with 'you'\n",
    "        return re.sub('me', 'you', message)\n",
    "    if 'my' in message:\n",
    "        # Replace 'my' with 'your'\n",
    "        return re.sub('my', 'your', message)\n",
    "    if 'your' in message:\n",
    "        # Replace 'your' with 'my'\n",
    "        return re.sub('your', 'my', message)\n",
    "    if 'you' in message:\n",
    "        # Replace 'you' with 'me'\n",
    "        return re.sub('you', 'me', message)\n",
    "    return message\n",
    "def respond(message):\n",
    "    # Call match_rule\n",
    "    response, phrase = match_rule(rules, message)\n",
    "    if '{0}' in response:\n",
    "        # Replace the pronouns in the phrase\n",
    "        phrase = replace_pronouns(phrase)\n",
    "        # Include the phrase in the response\n",
    "        response = response.format(phrase)\n",
    "    return response\n",
    "import random\n",
    "def match_rule(rules, message):\n",
    "    for pattern, responses in rules.items():\n",
    "        match = re.search(pattern, message)\n",
    "        if match is not None:\n",
    "            response = random.choice(responses)\n",
    "            var = match.group(1) if '{0}' in response else None\n",
    "            return response, var\n",
    "    return \"default\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : hello!\n",
      "BOT : Hello you! :)\n",
      "USER : bye byeee\n",
      "BOT : goodbye for now\n",
      "USER : thanks very much!\n",
      "BOT : you are very welcome\n"
     ]
    }
   ],
   "source": [
    "# Define a function to find the intent of a message\n",
    "def match_intent(message):\n",
    "    matched_intent = None\n",
    "    for intent, pattern in patterns.items():\n",
    "        # Check if the pattern occurs in the message \n",
    "        if pattern.search(message):\n",
    "            matched_intent = intent\n",
    "    return matched_intent\n",
    "responses = {'default': 'default message',\n",
    " 'goodbye': 'goodbye for now',\n",
    " 'greet': 'Hello you! :)',\n",
    " 'thankyou': 'you are very welcome'}\n",
    "# Define a respond function\n",
    "def respond(message):\n",
    "    # Call the match_intent function\n",
    "    intent = match_intent(message)\n",
    "    # Fall back to the default response\n",
    "    key = \"default\"\n",
    "    if intent in responses:\n",
    "        key = intent\n",
    "    return responses[key]\n",
    "\n",
    "# Send messages\n",
    "send_message(\"hello!\")\n",
    "send_message(\"bye byeee\")\n",
    "send_message(\"thanks very much!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, David Copperfield!\n",
      "Hello, Ishmael!\n",
      "Hello, People Cassandra!\n"
     ]
    }
   ],
   "source": [
    "# m# Define find_name()\n",
    "import re\n",
    "def find_name(message):\n",
    "    name = None\n",
    "    # Create a pattern for checking if the keywords occur\n",
    "    name_keyword = re.compile('name|call(ed)?')\n",
    "    # Create a pattern for finding capitalized words\n",
    "    name_pattern = re.compile('[A-Z][a-z]*')\n",
    "    if name_keyword.search(message):\n",
    "        # Get the matching words in the string\n",
    "        name_words = name_pattern.findall(message)\n",
    "        if len(name_words) > 0:\n",
    "            # Return the name if the keywords are present\n",
    "            name = ' '.join(name_words)\n",
    "    return name\n",
    "\n",
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Find the name\n",
    "    name = find_name(message)\n",
    "    if name is None:\n",
    "        return \"Hi there!\"\n",
    "    else:\n",
    "        return \"Hello, {0}!\".format(name)\n",
    "\n",
    "# Send messages\n",
    "print(respond(\"my name is David Copperfield\"))\n",
    "print(respond(\"call me Ishmael\"))\n",
    "print(respond(\"People call me Cassandra\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER : my name is David Copperfield\n",
      "BOT : Hello, David Copperfield!\n",
      "USER : call me Ishmael\n",
      "BOT : Hello, Ishmael!\n",
      "USER : People call me Cassandra\n",
      "BOT : Hello, People Cassandra!\n"
     ]
    }
   ],
   "source": [
    "# Define find_name()\n",
    "def find_name(message):\n",
    "    name = None\n",
    "    # Create a pattern for checking if the keywords occur\n",
    "    name_keyword = re.compile('name|call')\n",
    "    # Create a pattern for finding capitalized words\n",
    "    name_pattern = re.compile('[A-Z]{1}[a-z]*')\n",
    "    if name_keyword.search(message):\n",
    "        # Get the matching words in the string\n",
    "        name_words = name_pattern.findall(message)\n",
    "        if len(name_words) > 0:\n",
    "            # Return the name if the keywords are present\n",
    "            name = ' '.join(name_words)\n",
    "    return name\n",
    "\n",
    "# Define respond()\n",
    "def respond(message):\n",
    "    # Find the name\n",
    "    name = find_name(message)\n",
    "    if name is None:\n",
    "        return \"Hi there!\"\n",
    "    else:\n",
    "        return \"Hello, {0}!\".format(name)\n",
    "\n",
    "# Send messages\n",
    "send_message(\"my name is David Copperfield\")\n",
    "send_message(\"call me Ishmael\")\n",
    "send_message(\"People call me Cassandra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [' i want to fly from boston at 838 am and arrive in denver at 1110 in the morning',\n",
    " ' what flights are available from pittsburgh to baltimore on thursday morning',\n",
    " ' what is the arrival time in san francisco for the 755 am flight leaving washington',\n",
    " ' cheapest airfare from tacoma to orlando',\n",
    " ' round trip fares from pittsburgh to philadelphia under 1000 dollars',\n",
    " ' i need a flight tomorrow from columbus to minneapolis',\n",
    " ' what kind of aircraft is used on a flight from cleveland to dallas',\n",
    " ' show me the flights from pittsburgh to los angeles on thursday',\n",
    " ' all flights from boston to washington',\n",
    " ' what kind of ground transportation is available in denver',\n",
    " ' show me the flights from dallas to san francisco',\n",
    " ' show me the flights from san diego to newark by way of houston',\n",
    " ' what is the cheapest flight from boston to bwi',\n",
    " ' all flights to baltimore after 6 pm',\n",
    " ' show me the first class fares from boston to denver',\n",
    " ' show me the ground transportation in denver',\n",
    " ' all flights from denver to pittsburgh leaving after 6 pm and before 7 pm',\n",
    " ' i need information on flights for tuesday leaving baltimore for dallas dallas to boston and boston to baltimore',\n",
    " ' please give me the flights from boston to pittsburgh on thursday of next week',\n",
    " ' i would like to fly from denver to pittsburgh on united airlines',\n",
    " ' show me the flights from san diego to newark',\n",
    " ' please list all first class flights on united from denver to baltimore',\n",
    " ' what kinds of planes are used by american airlines',\n",
    " \" i'd like to have some information on a ticket from denver to pittsburgh and atlanta\",\n",
    " \" i'd like to book a flight from atlanta to denver\",\n",
    " ' which airline serves denver pittsburgh and atlanta',\n",
    " \" show me all flights from boston to pittsburgh on wednesday of next week which leave boston after 2 o'clock pm\",\n",
    " ' atlanta ground transportation',\n",
    " ' i also need service from dallas to boston arriving by noon',\n",
    " ' show me the cheapest round trip fare from baltimore to dallas']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.2/12.8 MB 3.5 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.5/12.8 MB 5.6 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.6/12.8 MB 5.1 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.0/12.8 MB 5.7 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.3/12.8 MB 6.0 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 5.6 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.6/12.8 MB 5.6 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.0/12.8 MB 4.7 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 2.1/12.8 MB 4.7 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.3/12.8 MB 4.8 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.5/12.8 MB 4.6 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.8/12.8 MB 4.9 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 3.1/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.5/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.1/12.8 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.3/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.5/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.8/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.1/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.9/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.1/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.2/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.4/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.6/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.9/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.8/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 8.1/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.4/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.1/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.2/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.5/12.8 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 5.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (66.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jdamodhar\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\jdamodhar\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jdamodhar\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'PRON'), ('is', 'AUX'), ('a', 'DET'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "print([(w.text, w.pos_) for w in doc])\n",
    "nlp.vocab.vectors_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (96,) into shape (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\92-Building Chatbots in Python\\02-Understanding natural language.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/92-Building%20Chatbots%20in%20Python/02-Understanding%20natural%20language.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(sentence)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/92-Building%20Chatbots%20in%20Python/02-Understanding%20natural%20language.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Save the document's .vector attribute to the corresponding row in X\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/92-Building%20Chatbots%20in%20Python/02-Understanding%20natural%20language.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m X[idx, :] \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39mvector\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (96,) into shape (0,)"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# Load the spacy model: nlp\n",
    "# nlp = spacy.load('en')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the length of sentences\n",
    "n_sentences = len(sentences)\n",
    "\n",
    "# Calculate the dimensionality of nlp\n",
    "embedding_dim = nlp.vocab.vectors_length\n",
    "\n",
    "# Initialize the array with zeros: X\n",
    "X = np.zeros((n_sentences, embedding_dim))\n",
    "\n",
    "# Iterate over the sentences\n",
    "for idx, sentence in enumerate(sentences):\n",
    "    # Pass each each sentence to the nlp object to create a document\n",
    "    doc = nlp(sentence)\n",
    "    # Save the document's .vector attribute to the corresponding row in X\n",
    "    X[idx, :] = doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create a support vector classifier with C=1\n",
    "clf = SVC(C=1)\n",
    "\n",
    "# Fit the classifier using the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Count the number of correct predictions\n",
    "n_correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        n_correct += 1\n",
    "\n",
    "print(\"Predicted {0} correctly out of {1} test examples\".format(n_correct, len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary PERSON\n",
      "Google ORG\n",
      "2009 DATE\n"
     ]
    }
   ],
   "source": [
    "import spacy  \n",
    "nlp = spacy.load('en_core_web_sm')  \n",
    "doc = nlp(\"my friend Mary has worked at Google since 2009\")  \n",
    "for ent in doc.ents:     \n",
    "    print(ent.text, ent.label_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATE': '2010', 'ORG': 'Google', 'PERSON': 'Mary'}\n",
      "{'DATE': '1999', 'ORG': 'MIT', 'PERSON': None}\n"
     ]
    }
   ],
   "source": [
    "# Define included_entities\n",
    "include_entities = ['DATE', 'ORG', 'PERSON']\n",
    "\n",
    "# Define extract_entities()\n",
    "def extract_entities(message):\n",
    "    # Create a dict to hold the entities\n",
    "    ents = dict.fromkeys(include_entities)\n",
    "    # Create a spacy document\n",
    "    doc = nlp(message)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in include_entities:\n",
    "            # Save interesting entities\n",
    "            ents[ent.label_] = ent.text\n",
    "    return ents\n",
    "\n",
    "print(extract_entities('friends called Mary who have worked at Google since 2010'))\n",
    "print(extract_entities('people who graduated from MIT in 1999'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = ['black', 'red', 'blue']\n",
    "items = ['shoes', 'handback', 'jacket', 'jeans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_type(word):\n",
    "    _type = None\n",
    "    if word.text in colors:\n",
    "        _type = \"color\"\n",
    "    elif word.text in items:\n",
    "        _type = \"item\"\n",
    "    return _type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: jacket has color : red\n",
      "item: jeans has color : blue\n"
     ]
    }
   ],
   "source": [
    "# Create the document\n",
    "doc = nlp(\"let's see that jacket in red and some blue jeans\")\n",
    "\n",
    "# Iterate over parents in parse tree until an item entity is found\n",
    "def find_parent_item(word):\n",
    "    # Iterate over the word's ancestors\n",
    "    for parent in word.ancestors:\n",
    "        # Check for an \"item\" entity\n",
    "        if entity_type(parent) == \"item\":\n",
    "            return parent.text\n",
    "    return None\n",
    "\n",
    "# For all color entities, find their parent item\n",
    "def assign_colors(doc):\n",
    "    # Iterate over the document\n",
    "    for word in doc:\n",
    "        # Check for \"color\" entities\n",
    "        if entity_type(word) == \"color\":\n",
    "            # Find the parent\n",
    "            item =  find_parent_item(word)\n",
    "            print(\"item: {0} has color : {1}\".format(item, word))\n",
    "\n",
    "# Assign the colors\n",
    "assign_colors(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rasa-nlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rasa-nlu --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rasa-plus --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rasa_nlu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\92-Building Chatbots in Python\\02-Understanding natural language.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/92-Building%20Chatbots%20in%20Python/02-Understanding%20natural%20language.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Import necessary modules\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/92-Building%20Chatbots%20in%20Python/02-Understanding%20natural%20language.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrasa_nlu\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m load_data\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/92-Building%20Chatbots%20in%20Python/02-Understanding%20natural%20language.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrasa_nlu\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m RasaNLUConfig\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/92-Building%20Chatbots%20in%20Python/02-Understanding%20natural%20language.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrasa_nlu\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rasa_nlu'"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from rasa_nlu.converters import load_data\n",
    "from rasa_nlu.config import RasaNLUConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "\n",
    "# Create args dictionary\n",
    "args = {\"pipeline\": \"spacy_sklearn\"}\n",
    "\n",
    "# Create a configuration and trainer\n",
    "config = RasaNLUConfig(cmdline_args=args)\n",
    "trainer = Trainer(config)\n",
    "\n",
    "# Load the training data\n",
    "training_data = load_data(\"./training_data.json\")\n",
    "\n",
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# Test the interpreter\n",
    "\n",
    "print(interpreter.parse(\"I'm looking for a Mexican restaurant in the North of town\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from rasa_nlu.config import RasaNLUConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "\n",
    "pipeline = [\n",
    "    \"nlp_spacy\",\n",
    "    \"tokenizer_spacy\",\n",
    "    \"ner_crf\"\n",
    "]\n",
    "\n",
    "# Create a config that uses this pipeline\n",
    "config = RasaNLUConfig(cmdline_args={\"pipeline\": pipeline})\n",
    "\n",
    "# Create a trainer that uses this config\n",
    "trainer = Trainer(config)\n",
    "\n",
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# Parse some messages\n",
    "print(interpreter.parse(\"show me Chinese food in the centre of town\"))\n",
    "print(interpreter.parse(\"I want an Indian restaurant in the west\"))\n",
    "print(interpreter.parse(\"are there any good pizza places in the center?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
