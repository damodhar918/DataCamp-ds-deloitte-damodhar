{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'spacy.matcher' has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\93-Advanced NLP with spaCy\\04-Training a neural network model.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/93-Advanced%20NLP%20with%20spaCy/04-Training%20a%20neural%20network%20model.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pattern2 \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mLOWER\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39miphone\u001b[39m\u001b[39m'\u001b[39m}, {\u001b[39m'\u001b[39m\u001b[39mIS_DIGIT\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mOP\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m?\u001b[39m\u001b[39m'\u001b[39m}]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/93-Advanced%20NLP%20with%20spaCy/04-Training%20a%20neural%20network%20model.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Add patterns to the matcher\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/93-Advanced%20NLP%20with%20spaCy/04-Training%20a%20neural%20network%20model.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m matcher\u001b[39m.\u001b[39;49madd(\u001b[39m'\u001b[39m\u001b[39mGADGET\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m, pattern1, pattern2)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'spacy.matcher' has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "# Two tokens whose lowercase forms match 'iphone' and 'x'\n",
    "pattern1 = [{'LOWER': 'iphone'}, {'LOWER': 'x'}]\n",
    "\n",
    "# Token whose lowercase form matches 'iphone' and an optional digit\n",
    "pattern2 = [{'LOWER': 'iphone'}, {'IS_DIGIT': True, 'OP': '?'}]\n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add('GADGET', None, pattern1, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "# Initialize a matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define patterns\n",
    "pattern1 = [{'LOWER': 'smartphone'}, {'IS_DIGIT': True}]\n",
    "pattern2 = [{'LOWER': 'iphone'}, {'IS_DIGIT': True, 'OP': '?'}]\n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add('GADGET', [pattern1])\n",
    "matcher.add('GADGET', [pattern2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXTS = ['How to preorder the iPhone X',\n",
    " 'iPhone X is coming',\n",
    " 'Should I pay $1,000 for the iPhone X?',\n",
    " 'The iPhone 8 reviews are here',\n",
    " 'Your iPhone goes up to 11 today',\n",
    " 'I need a new phone! Any tips?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to preorder the iPhone X [(4, 5, 'GADGET')]\n",
      "iPhone X is coming [(0, 1, 'GADGET')]\n",
      "Should I pay $1,000 for the iPhone X? [(7, 8, 'GADGET')]\n",
      "The iPhone 8 reviews are here [(1, 2, 'GADGET'), (1, 3, 'GADGET')]\n",
      "Your iPhone goes up to 11 today [(1, 2, 'GADGET')]\n",
      "I need a new phone! Any tips? []\n"
     ]
    }
   ],
   "source": [
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    # Find the matches in the doc\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    # Get a list of (start, end, label) tuples of matches in the text\n",
    "    entities = [(start, end, 'GADGET') for match_id, start, end in matches]\n",
    "    print(doc.text, entities)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How to preorder the iPhone X', {'entities': [(20, 26, 'GADGET')]})\n",
      "('iPhone X is coming', {'entities': [(0, 6, 'GADGET')]})\n",
      "('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 34, 'GADGET')]})\n",
      "('The iPhone 8 reviews are here', {'entities': [(4, 10, 'GADGET'), (4, 12, 'GADGET')]})\n",
      "('Your iPhone goes up to 11 today', {'entities': [(5, 11, 'GADGET')]})\n",
      "('I need a new phone! Any tips?', {'entities': []})\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = []\n",
    "\n",
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    # Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    # Get (start character, end character, label) tuples of matches\n",
    "    entities = [(span.start_char, span.end_char, 'GADGET') for span in spans]\n",
    "    \n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc.text, {'entities': entities})\n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)\n",
    "    \n",
    "print(*TRAINING_DATA, sep='\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a blank 'en' model\n",
    "import spacy\n",
    "# nlp = spacy.blank('en')\n",
    "\n",
    "# Create a new entity recognizer and add it to the pipeline\n",
    "ner = nlp.create_pipe('ner')\n",
    "nlp.add_pipe('ner')\n",
    "\n",
    "# Add the label 'GADGET' to the entity recognizer\n",
    "ner.add_label('GADGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training\n",
    "nlp.begin_training()\n",
    "import random\n",
    "# Loop for 10 iterations\n",
    "for itn in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "[E978] The Language.update method takes a list of Example objects, but got: {<class 'str'>}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\93-Advanced NLP with spaCy\\04-Training a neural network model.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/93-Advanced%20NLP%20with%20spaCy/04-Training%20a%20neural%20network%20model.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m annotations \u001b[39m=\u001b[39m [entities \u001b[39mfor\u001b[39;00m text, entities \u001b[39min\u001b[39;00m batch]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/93-Advanced%20NLP%20with%20spaCy/04-Training%20a%20neural%20network%20model.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Update the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/93-Advanced%20NLP%20with%20spaCy/04-Training%20a%20neural%20network%20model.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m nlp\u001b[39m.\u001b[39;49mupdate(texts, losses\u001b[39m=\u001b[39;49mlosses)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/93-Advanced%20NLP%20with%20spaCy/04-Training%20a%20neural%20network%20model.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(losses)\n",
      "File \u001b[1;32mc:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:1176\u001b[0m, in \u001b[0;36mLanguage.update\u001b[1;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(examples, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(examples) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1175\u001b[0m     \u001b[39mreturn\u001b[39;00m losses\n\u001b[1;32m-> 1176\u001b[0m validate_examples(examples, \u001b[39m\"\u001b[39;49m\u001b[39mLanguage.update\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   1177\u001b[0m examples \u001b[39m=\u001b[39m _copy_examples(examples)\n\u001b[0;32m   1178\u001b[0m \u001b[39mif\u001b[39;00m sgd \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\training\\example.pyx:57\u001b[0m, in \u001b[0;36mspacy.training.example.validate_examples\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: [E978] The Language.update method takes a list of Example objects, but got: {<class 'str'>}"
     ]
    }
   ],
   "source": [
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for itn in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "    \n",
    "    # Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "        \n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations, losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of Example objects\n",
    "examples = []\n",
    "for text, entities in zip(texts, annotations):\n",
    "    examples.append(Example.from_dict(nlp.make_doc(text), entities))\n",
    "\n",
    "# Update the model\n",
    "nlp.update(examples, losses=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA = ['Apple is slowing down the iPhone 8 and iPhone X - how to stop it',\n",
    " \"I finally understand what the iPhone X 'notch' is for\",\n",
    " 'Everything you need to know about the Samsung Galaxy S9',\n",
    " 'Looking to compare iPad models? Here’s how the 2018 lineup stacks up',\n",
    " 'The iPhone 8 and iPhone 8 Plus are smartphones designed, developed, and marketed by Apple',\n",
    " 'what is the cheapest ipad, especially ipad pro???',\n",
    " 'Samsung Galaxy is a series of mobile computing devices designed, manufactured and marketed by Samsung Electronics']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is slowing down the iPhone 8 and iPhone X - how to stop it\n",
      "() \n",
      "\n",
      "\n",
      "I finally understand what the iPhone X 'notch' is for\n",
      "() \n",
      "\n",
      "\n",
      "Everything you need to know about the Samsung Galaxy S9\n",
      "() \n",
      "\n",
      "\n",
      "Looking to compare iPad models? Here’s how the 2018 lineup stacks up\n",
      "() \n",
      "\n",
      "\n",
      "The iPhone 8 and iPhone 8 Plus are smartphones designed, developed, and marketed by Apple\n",
      "() \n",
      "\n",
      "\n",
      "what is the cheapest ipad, especially ipad pro???\n",
      "() \n",
      "\n",
      "\n",
      "Samsung Galaxy is a series of mobile computing devices designed, manufactured and marketed by Samsung Electronics\n",
      "() \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process each text in TEST_DATA\n",
    "for doc in nlp.pipe(TEST_DATA):\n",
    "    # Print the document text and entitites\n",
    "    print(doc.text)\n",
    "    print(doc.ents, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i went to amsterdem last year and the canals were beautiful', {'entities': [(10, 19, 'GPE')]})\n",
      "('You should visit Paris once in your life, but the Eiffel Tower is kinda boring', {'entities': [(17, 22, 'GPE')]})\n",
      "(\"There's also a Paris in Arkansas, lol\", {'entities': [(15, 20, 'GPE'), (24, 32, 'GPE')]})\n",
      "('Berlin is perfect for summer holiday: lots of parks, great nightlife, cheap beer!', {'entities': [(0, 6, 'GPE')]})\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = [\n",
    "    (\"i went to amsterdem last year and the canals were beautiful\", {'entities': [(10, 19, 'GPE')]}),\n",
    "    (\"You should visit Paris once in your life, but the Eiffel Tower is kinda boring\", {'entities': [(17, 22, 'GPE')]}),\n",
    "    (\"There's also a Paris in Arkansas, lol\", {'entities': [(15, 20, 'GPE'), (24, 32, 'GPE')]}),\n",
    "    (\"Berlin is perfect for summer holiday: lots of parks, great nightlife, cheap beer!\", {'entities': [(0, 6, 'GPE')]})\n",
    "]\n",
    "\n",
    "print(*TRAINING_DATA, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA = [\n",
    "    (\"Reddit partners with Patreon to help creators build communities\", \n",
    "     {'entities': [(0, 6, 'WEBSITE'), (21, 28, 'WEBSITE')]}),\n",
    "  \n",
    "    (\"PewDiePie smashes YouTube record\", \n",
    "     {'entities': [(0, 9, 'PERSON'), (18, 25, 'WEBSITE')]}),\n",
    "  \n",
    "    (\"Reddit founder Alexis Ohanian gave away two Metallica tickets to fans\", \n",
    "     {'entities': [(0, 6, 'WEBSITE'), (15, 29, 'PERSON')]}),\n",
    "    # And so on...\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
