{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon = pd.read_csv('pokemon.csv', index_col='#')\n",
    "pokemon.head()\n",
    "X = pokemon[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Generation']]\n",
    "y = pokemon['Legendary']\n",
    "# Split into train (80%) and test (20%) sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[143   7]\n",
      " [  3   7]]\n",
      "F1-Score: 0.583\n",
      "Confusion matrix:\n",
      " [[148   2]\n",
      " [  5   5]]\n",
      "F1-Score: 0.588\n"
     ]
    }
   ],
   "source": [
    "# Build unrestricted decision tree\n",
    "clf = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('Confusion matrix:\\n', cm)\n",
    "\n",
    "# Print the F1 score\n",
    "score = f1_score(y_test, pred)\n",
    "print('F1-Score: {:.3f}'.format(score))\n",
    "\n",
    "# Build restricted decision tree\n",
    "clf2 = DecisionTreeClassifier(max_depth=4, max_features=2)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "pred2 = clf2.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm2 = confusion_matrix(y_test, pred2)\n",
    "print('Confusion matrix:\\n', cm2)\n",
    "\n",
    "# Print the F1 score\n",
    "score2 = f1_score(y_test, pred2)\n",
    "print('F1-Score: {:.3f}'.format(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[146   4]\n",
      " [  5   5]]\n",
      "F1-Score: 0.526\n",
      "Confusion matrix:\n",
      " [[145   5]\n",
      " [  6   4]]\n",
      "F1-Score: 0.421\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build unrestricted decision tree\n",
    "clf = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, \n",
    "max_depth=4, max_features=2,\n",
    "random_state=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('Confusion matrix:\\n', cm)\n",
    "\n",
    "# Print the F1 score\n",
    "score = f1_score(y_test, pred)\n",
    "print('F1-Score: {:.3f}'.format(score))\n",
    "\n",
    "# Build restricted decision tree\n",
    "clf2 = DecisionTreeClassifier(max_depth=4, max_features=2)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "pred2 = clf2.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "cm2 = confusion_matrix(y_test, pred2)\n",
    "print('Confusion matrix:\\n', cm2)\n",
    "\n",
    "# Print the F1 score\n",
    "score2 = f1_score(y_test, pred2)\n",
    "print('F1-Score: {:.3f}'.format(score2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Weak\" decision tree\n",
    "In the previous exercise you built two decision trees. Which one is fine-tuned and which one is \"weak\"?\n",
    "\n",
    "Decision tree \"A\":\n",
    "\n",
    "min_samples_leaf = 3 and min_samples_split = 9\n",
    "F1-Score: ~58%\n",
    "Decision tree \"B\":\n",
    "\n",
    "max_depth = 4 and max_features = 2\n",
    "F1-Score: ~53%\n",
    "Both classifiers are available for you as clf_A and clf_B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct choice! Model A is a fine-tuned decision tree, with a decent performance on its own. Model B is 'weak', restricted in height and with performance just above 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((640, 7), (640,)), ((640, 7), (640,)))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon = pd.read_csv('pokemon.csv', index_col='#')\n",
    "pokemon.head()\n",
    "X = pokemon[['HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed', 'Generation']]\n",
    "y = pokemon['Legendary']\n",
    "# Split into train (80%) and test (20%) sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Take a sample with replacement\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_train_sample = X_train.sample(frac=1.0, replace=True, random_state=42)\n",
    "y_train_sample = y_train.loc[X_train_sample.index].reset_index(drop=True)\n",
    "(X_train.shape,y_train.shape),(X_train_sample.shape,y_train_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>45</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>95</td>\n",
       "      <td>117</td>\n",
       "      <td>184</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>50</td>\n",
       "      <td>95</td>\n",
       "      <td>180</td>\n",
       "      <td>85</td>\n",
       "      <td>45</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>70</td>\n",
       "      <td>77</td>\n",
       "      <td>60</td>\n",
       "      <td>97</td>\n",
       "      <td>60</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>105</td>\n",
       "      <td>165</td>\n",
       "      <td>110</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HP  Attack  Defense  Sp. Atk  Sp. Def  Speed  Generation\n",
       "102  45      22       60       27       30     29           6\n",
       "435  35      35       40       35       55     50           2\n",
       "270  95     117      184       44       46     28           6\n",
       "106  70      90       70       60       60     70           3\n",
       "71   40      55       30       30       30     85           3\n",
       "..   ..     ...      ...      ...      ...    ...         ...\n",
       "404  28      25       25       45       35     40           3\n",
       "517  50      95      180       85       45     70           1\n",
       "475  70      77       60       97       60    108           5\n",
       "436  53      51       53       61       56     40           4\n",
       "22   90      95      105      165      110     45           2\n",
       "\n",
       "[640 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 7)\n",
      "(640,)\n",
      "Legendary\n",
      "False    580\n",
      "True      60\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train_sample.shape)\n",
    "print(y_train_sample.shape)\n",
    "print(y_train_sample.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=4, random_state=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=4, random_state=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4, random_state=500)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=4, random_state=500)\n",
    "\n",
    "# Take a sample with replacement\n",
    "X_train_sample = X_train.sample(frac=1.0, replace=True, random_state=42)\n",
    "y_train_sample = y_train.loc[X_train_sample.index]\n",
    "\n",
    "# Fit the model to the training sample\n",
    "clf.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_voting(classifiers, X):\n",
    "# \t# Make the individual predictions\n",
    "# \tpred_list = [clf.predict(X) for clf in classifiers]\n",
    "\t\n",
    "# \t# Combine the predictions using \"Voting\"\n",
    "# \tpred_vote = []\n",
    "# \tfor i in range(X.shape[0]):\n",
    "# \t\tindividual_preds = np.array([pred[i] for pred in pred_list])\n",
    "# \t\tcombined_pred = stats.mode(individual_preds)[0][0]\n",
    "# \t\tpred_vote.insert(i, combined_pred)\n",
    "\t\n",
    "# \treturn pred_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "def predict_voting(classifiers, X):\n",
    "    pred_list = []\n",
    "    for clf in classifiers:\n",
    "        pred_list.append(clf.predict(X))\n",
    "        \n",
    "    # Combine the predictions using \"Voting\"\n",
    "    pred_vote = []\n",
    "    for i in range(X.shape[0]):\n",
    "        individual_preds = np.array([pred[i] for pred in pred_list])\n",
    "        unique, counts = np.unique(individual_preds, return_counts=True)\n",
    "        combined_pred = unique[np.argmax(counts)]\n",
    "        pred_vote.append(combined_pred)\n",
    "\n",
    "    return pred_vote\n",
    "def build_decision_tree(X_train, y_train, random_state=None):\n",
    "\t# Take a sample with replacement\n",
    "\tX_train_sample = X_train.sample(frac=1.0, replace=True, random_state=random_state)\n",
    "\ty_train_sample = y_train.loc[X_train_sample.index]\n",
    "\n",
    "\t# Build a \"weak\" Decision Tree classifier\n",
    "\tclf = DecisionTreeClassifier(max_depth=4, random_state=500)\n",
    "\n",
    "\t# Fit the model on the training sample\n",
    "\tclf.fit(X_train_sample, y_train_sample)\n",
    "\t\n",
    "\treturn clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.632\n"
     ]
    }
   ],
   "source": [
    "# Build the list of individual models\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_list = []\n",
    "for i in range(21):\n",
    "    weak_dt = build_decision_tree(X_train, y_train, random_state=i)\n",
    "    clf_list.append(weak_dt)\n",
    "\n",
    "# Predict on the test set\n",
    "pred = predict_voting(clf_list, X_test)\n",
    "\n",
    "# Print the F1 score\n",
    "print('F1 score: {:.3f}'.format(f1_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.667\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the base model\n",
    "clf_dt = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "# Build and train the Bagging classifier\n",
    "clf_bag = BaggingClassifier(\n",
    "  clf_dt,\n",
    "  n_estimators=21,\n",
    "  random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "pred = clf_bag.predict(X_test)\n",
    "\n",
    "# Show the F1-score\n",
    "print('F1-Score: {:.3f}'.format(f1_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9328125\n"
     ]
    }
   ],
   "source": [
    "# Build and train the bagging classifier\n",
    "clf_bag = BaggingClassifier(\n",
    "  estimator=clf_dt,\n",
    "  n_estimators=21,\n",
    "  oob_score=True,\n",
    "  random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Print the classifier's out-of-bag score\n",
    "print(clf_bag.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB-Score: 0.933\n",
      "Accuracy: 0.963\n",
      "F1-Score: 0.667\n"
     ]
    }
   ],
   "source": [
    "# Print the out-of-bag score\n",
    "print('OOB-Score: {:.3f}'.format(clf_bag.oob_score_))\n",
    "\n",
    "# Evaluate the performance on the test set to compare\n",
    "pred = clf_bag.predict(X_test)\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, pred)))\n",
    "# Show the F1-score\n",
    "print('F1-Score: {:.3f}'.format(f1_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci = pd.read_csv('./uci-secom.csv', index_col='Time', parse_dates=True)\n",
    "\n",
    "X = uci.drop('Pass/Fail', axis=1)\n",
    "X = X.fillna(X.median())\n",
    "y = uci['Pass/Fail']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.77\n",
      "OOB-Score: 0.68\n",
      "[[236  60]\n",
      " [ 13   5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:789: UserWarning: Some inputs do not have OOB scores. This probably means too few estimators were used to compute any reliable oob estimates.\n",
      "  warn(\n",
      "c:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:795: RuntimeWarning: invalid value encountered in divide\n",
      "  oob_decision_function = predictions / predictions.sum(axis=1)[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Build a balanced logistic regression\n",
    "clf_lr = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)\n",
    "\n",
    "# Build and fit a bagging classifier\n",
    "clf_bag = BaggingClassifier(clf_lr, oob_score=True, max_features=10, random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy on the test set and show the out-of-bag score\n",
    "pred = clf_bag.predict(X_test)\n",
    "print('Accuracy:  {:.2f}'.format(accuracy_score(y_test, pred)))\n",
    "print('OOB-Score: {:.2f}'.format(clf_bag.oob_score_))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.78      0.86       296\n",
      "           1       0.10      0.39      0.15        18\n",
      "\n",
      "    accuracy                           0.75       314\n",
      "   macro avg       0.53      0.58      0.51       314\n",
      "weighted avg       0.91      0.75      0.82       314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a balanced logistic regression\n",
    "clf_base = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)\n",
    "\n",
    "# Build and fit a bagging classifier with custom parameters\n",
    "clf_bag = BaggingClassifier(estimator=clf_base, n_estimators=20, max_features=10, max_samples=0.65, bootstrap=False, random_state=500)\n",
    "clf_bag.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions and evaluate the accuracy on the test set\n",
    "y_pred = clf_bag.predict(X_test)\n",
    "print('Accuracy:  {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
