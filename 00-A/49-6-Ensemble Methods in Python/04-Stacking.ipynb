{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Naive Bayes classifier\n",
    "clf_nb = GaussianNB()\n",
    "\n",
    "# Fit the model to the training set\n",
    "clf_nb.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = clf_nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the accuracy score\n",
    "print(\"Accuracy: {:0.4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a 5-nearest neighbors classifier with 'ball_tree' algorithm\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree')\n",
    "\n",
    "# Fit the model to the training set\n",
    "clf_knn.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the predictions on the test set\n",
    "pred = clf_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance using the accuracy score\n",
    "print(\"Accuracy: {:0.4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and fit a Decision Tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "\n",
    "# Build and fit a 5-nearest neighbors classifier using the 'Ball-Tree' algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree')\n",
    "clf_knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance using the accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Decision Tree: {:0.4f}'.format(accuracy_score(clf_dt.predict(X_test), y_test)))\n",
    "print('5-Nearest Neighbors: {:0.4f}'.format(accuracy_score(clf_knn.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the list of tuples with the first-layer classifiers\n",
    "classifiers = [\n",
    "\t('clf_dt', clf_dt),\n",
    "    ('clf_knn', clf_knn)\n",
    "]\n",
    "\n",
    "# Instantiate the second-layer meta estimator\n",
    "clf_meta = LogisticRegression()\n",
    "\n",
    "# Build the stacking classifier\n",
    "clf_stack = StackingClassifier(\n",
    "   estimators=classifiers,\n",
    "   final_estimator=clf_meta,\n",
    "   stack_method='predict_proba',\n",
    "   passthrough=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the stacking classifier to the training set\n",
    "clf_stack.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the final predictions from the stacking classifier\n",
    "pred_stack = clf_stack.predict(X_test)\n",
    "\n",
    "# Evaluate the new performance on the test set\n",
    "print('Accuracy: {:0.4f}'.format(accuracy_score(y_test, pred_stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the first-layer classifiers\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=3, min_samples_split=9, random_state=500)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree')\n",
    "\n",
    "# Instantiate the second-layer meta classifier\n",
    "clf_meta = LogisticRegression()\n",
    "\n",
    "# Build the Stacking classifier\n",
    "clf_stack = StackingClassifier(\n",
    "    classifiers=[clf_dt, clf_knn], \n",
    "    meta_classifier=clf_meta, \n",
    "    use_probas=True, \n",
    "    use_features_in_secondary=False\n",
    ")\n",
    "clf_stack.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance of the Stacking classifier\n",
    "pred_stack = clf_stack.predict(X_test)\n",
    "print(\"Accuracy: {:0.4f}\".format(accuracy_score(y_test, pred_stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\49-6-Ensemble Methods in Python\\04-Stacking.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/49-6-Ensemble%20Methods%20in%20Python/04-Stacking.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Instantiate the 1st-layer regressors\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/49-6-Ensemble%20Methods%20in%20Python/04-Stacking.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m reg_dt \u001b[39m=\u001b[39m DecisionTreeRegressor(min_samples_leaf\u001b[39m=\u001b[39m\u001b[39m11\u001b[39m, min_samples_split\u001b[39m=\u001b[39m\u001b[39m33\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/49-6-Ensemble%20Methods%20in%20Python/04-Stacking.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m reg_lr \u001b[39m=\u001b[39m LinearRegression()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/49-6-Ensemble%20Methods%20in%20Python/04-Stacking.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m reg_ridge \u001b[39m=\u001b[39m Ridge(random_state\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate the 1st-layer regressors\n",
    "reg_dt = DecisionTreeRegressor(min_samples_leaf=11, min_samples_split=33, random_state=500)\n",
    "reg_lr = LinearRegression()\n",
    "reg_ridge = Ridge(random_state=500)\n",
    "\n",
    "# Instantiate the 2nd-layer regressor\n",
    "reg_meta = LinearRegression()\n",
    "\n",
    "# Build the Stacking regressor\n",
    "reg_stack = StackingRegressor(regressors=[reg_dt, reg_lr, reg_ridge], meta_regressor=reg_meta)\n",
    "reg_stack.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the performance on the test set using the MAE metric\n",
    "pred = reg_stack.predict(X_test)\n",
    "print('MAE: {:.3f}'.format(mean_absolute_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the first-layer models\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5, algorithm='ball_tree')\n",
    "clf_dt = DecisionTreeClassifier(min_samples_leaf=5, min_samples_split=15, random_state=500)\n",
    "clf_nb = GaussianNB()\n",
    "\n",
    "# Create the second-layer model (meta-model)\n",
    "clf_lr = LogisticRegression()\n",
    "\n",
    "# Create and fit the stacked model\n",
    "clf_stack = StackingClassifier(classifiers=[clf_knn, clf_dt, clf_nb], meta_classifier=clf_lr)\n",
    "clf_stack.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the stacked modelâ€™s performance\n",
    "print(\"Accuracy: {:0.4f}\".format(accuracy_score(y_test, clf_stack.predict(X_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
