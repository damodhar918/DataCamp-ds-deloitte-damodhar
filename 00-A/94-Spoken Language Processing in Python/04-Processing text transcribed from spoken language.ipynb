{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ./ex4_call_1_stereo_mp3.mp3 to .wav...\n"
     ]
    }
   ],
   "source": [
    "# Create function to convert audio file to wav\n",
    "def convert_to_wav(filename):\n",
    "  \"\"\"Takes an audio file of non .wav format and converts to .wav\"\"\"\n",
    "  # Import audio file\n",
    "  audio = AudioSegment.from_file(filename)\n",
    "  \n",
    "  # Create new filename\n",
    "  new_filename = filename.split(\".\")[0] + \".wav\"\n",
    "  \n",
    "  # Export file as .wav\n",
    "  audio.export(new_filename, format=\"wav\")\n",
    "  print(f\"Converting {filename} to {new_filename}...\")\n",
    " \n",
    "# Test the function\n",
    "convert_to_wav(\"./ex4_call_1_stereo_mp3.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 1\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 2\n",
      "Length (ms): 54888\n"
     ]
    }
   ],
   "source": [
    "def show_pydub_stats(filename):\n",
    "  \"\"\"Returns different audio attributes related to an audio file.\"\"\"\n",
    "  # Create AudioSegment instance\n",
    "  audio_segment = AudioSegment.from_file(filename)\n",
    "  \n",
    "  # Print audio attributes and return AudioSegment instance\n",
    "  print(f\"Channels: {audio_segment.channels}\")\n",
    "  print(f\"Sample width: {audio_segment.sample_width}\")\n",
    "  print(f\"Frame rate (sample rate): {audio_segment.frame_rate}\")\n",
    "  print(f\"Frame width: {audio_segment.frame_width}\")\n",
    "  print(f\"Length (ms): {len(audio_segment)}\")\n",
    "  return audio_segment\n",
    "\n",
    "# Try the function\n",
    "call_1_audio_segment = show_pydub_stats(\"./ex4_call_1_stereo_mp3.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello welcome to acme Studio support on my name is Daniel how can I best help you John\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "def transcribe_audio(filename):\n",
    "  \"\"\"Takes a .wav format audio file and transcribes it to text.\"\"\"\n",
    "  # Setup a recognizer instance\n",
    "  recognizer = sr.Recognizer()\n",
    "  \n",
    "  # Import the audio file and convert to audio data\n",
    "  audio_file = sr.AudioFile(filename)\n",
    "  with audio_file as source:\n",
    "    audio_data = recognizer.record(source)\n",
    "  \n",
    "  # Return the transcribed text\n",
    "  return recognizer.recognize_google(audio_data)\n",
    "\n",
    "# Test the function\n",
    "print(transcribe_audio(\".wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ./ex4_call_1_stereo_mp3.mp3 to .wav...\n",
      "Channels: 1\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 2\n",
      "Length (ms): 54888\n"
     ]
    }
   ],
   "source": [
    "# Convert mp3 file to wav\n",
    "convert_to_wav(\"./ex4_call_1_stereo_mp3.mp3\")\n",
    "\n",
    "# Check the stats of new file\n",
    "call_1 = show_pydub_stats(\".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting call_1.mp3 to call_1.wav...\n",
      "Channels: 1\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 2\n",
      "Length (ms): 54888\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\94-Spoken Language Processing in Python\\04-Processing text transcribed from spoken language.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m call_1_split \u001b[39m=\u001b[39m call_1\u001b[39m.\u001b[39msplit_to_mono()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Export channel 2 (the customer channel)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m call_1_split[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mexport(\u001b[39m\"\u001b[39m\u001b[39m./ex4_call_1_channel_2_split.wav\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                        \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwav\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Convert mp3 file to wav\n",
    "convert_to_wav(\"call_1.mp3\")\n",
    "\n",
    "# Check the stats of new file\n",
    "call_1 = show_pydub_stats(\"call_1.wav\")\n",
    "\n",
    "# Split call_1 to mono\n",
    "call_1_split = call_1.split_to_mono()\n",
    "\n",
    "# Export channel 2 (the customer channel)\n",
    "call_1_split[1].export(\"./ex4_call_1_channel_2_split.wav\",\n",
    "                       format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list does not have an index of 1\n"
     ]
    }
   ],
   "source": [
    "call_1_split = call_1.split_to_mono()\n",
    "if len(call_1_split) >= 2:\n",
    "    call_1_split[1].export(\"./ex4_call_1_channel_2_split.wav\", format=\"wav\")\n",
    "else:\n",
    "    print(\"The list does not have an index of 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting call_1.mp3 to call_1.wav...\n",
      "Channels: 1\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 32000\n",
      "Frame width: 2\n",
      "Length (ms): 54888\n",
      "hay Janu this is John Cena number it is 41757 and very nice contact\n"
     ]
    }
   ],
   "source": [
    "# Convert mp3 file to wav\n",
    "convert_to_wav(\"call_1.mp3\")\n",
    "\n",
    "# Check the stats of new file\n",
    "call_1 = show_pydub_stats(\"call_1.wav\")\n",
    "\n",
    "# Split call_1 to mono\n",
    "call_1_split = call_1.split_to_mono()\n",
    "\n",
    "# Export channel 2 (the customer channel)\n",
    "# call_1_split[1].export(\"call_1_channel_2.wav\",\n",
    "#                        format=\"wav\")\n",
    "\n",
    "# Transcribe the single channel\n",
    "print(transcribe_audio(\"./ex4_call_1_channel_2_split.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jdamodhar\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello my name is Daniel thank you for calling acme Studios how can I best help you find from you guys and extremely happy with it I am just\n",
      "{'neg': 0.0, 'neu': 0.632, 'pos': 0.368, 'compound': 0.9245}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Let's try it on one of our phone calls\n",
    "call_2_text = transcribe_audio(\"./call_2.wav\")\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(call_2_text)\n",
    "print(sid.polarity_scores(call_2_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is silly I personally purchased a smartphone from you guys and extremely happy with it I am just going to issue but not be more about the message bank I have Google location according to Google according to the map in some way because I think\n",
      "{'neg': 0.0, 'neu': 0.92, 'pos': 0.08, 'compound': 0.3708}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Transcribe customer channel of call 2\n",
    "call_2_channel_2_text = transcribe_audio(\"./ex4_call_2_channel_2_formatted.wav\")\n",
    "\n",
    "# Display text and sentiment polarity scores\n",
    "print(call_2_channel_2_text)\n",
    "print(sid.polarity_scores(call_2_channel_2_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is silly I personally purchased a smartphone from you guys and extremely happy with it I am just going to issue but not be more about the message bank I have Google location according to Google according to the map in some way because I think\n",
      "{'neg': 0.0, 'neu': 0.92, 'pos': 0.08, 'compound': 0.3708}\n"
     ]
    }
   ],
   "source": [
    "# Import sent_tokenize from nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Split call 2 channel 2 into sentences and score each\n",
    "for sentence in sent_tokenize(call_2_channel_2_text):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello and welcome to acme studios.\n",
      "{'neg': 0.0, 'neu': 0.625, 'pos': 0.375, 'compound': 0.4588}\n",
      "My name's Daniel.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "How can I best help you?\n",
      "{'neg': 0.0, 'neu': 0.303, 'pos': 0.697, 'compound': 0.7845}\n",
      "Hi Diane.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "This is paid on this call up to see the status of my, I'm proctor mortars at three weeks ago, and then service is terrible.\n",
      "{'neg': 0.114, 'neu': 0.886, 'pos': 0.0, 'compound': -0.4767}\n",
      "Okay, Peter, sorry to hear about that.\n",
      "{'neg': 0.159, 'neu': 0.61, 'pos': 0.232, 'compound': 0.1531}\n",
      "Hey, Peter, before we go on, do you mind just, uh, is there something going on with your microphone?\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "I can't quite hear you.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Is this any better?\n",
      "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "Yeah, that's much better.\n",
      "{'neg': 0.0, 'neu': 0.282, 'pos': 0.718, 'compound': 0.6249}\n",
      "And sorry, what was, what was it that you said when you first first started speaking?\n",
      "{'neg': 0.08, 'neu': 0.92, 'pos': 0.0, 'compound': -0.0772}\n",
      "So I ordered a product from you guys three weeks ago and, uh, it's, it's currently on July 1st and I haven't received a provocative, again, three weeks to a full four weeks down line.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "This service is terrible.\n",
      "{'neg': 0.508, 'neu': 0.492, 'pos': 0.0, 'compound': -0.4767}\n",
      "Okay.\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2263}\n",
      "Well, what's your order id?\n",
      "{'neg': 0.0, 'neu': 0.656, 'pos': 0.344, 'compound': 0.2732}\n",
      "I'll, uh, I'll start looking into that for you.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Six, nine, eight, seven five.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "Okay.\n",
      "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.2263}\n",
      "Thank you.\n",
      "{'neg': 0.0, 'neu': 0.286, 'pos': 0.714, 'compound': 0.3612}\n"
     ]
    }
   ],
   "source": [
    "# Import sent_tokenize from nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "call_2_channel_2_paid_api_text = \"Hello and welcome to acme studios. My name's Daniel. How can I best help you? Hi Diane. This is paid on this call up to see the status of my, I'm proctor mortars at three weeks ago, and then service is terrible. Okay, Peter, sorry to hear about that. Hey, Peter, before we go on, do you mind just, uh, is there something going on with your microphone? I can't quite hear you. Is this any better? Yeah, that's much better. And sorry, what was, what was it that you said when you first first started speaking?  So I ordered a product from you guys three weeks ago and, uh, it's, it's currently on July 1st and I haven't received a provocative, again, three weeks to a full four weeks down line. This service is terrible. Okay. Well, what's your order id? I'll, uh, I'll start looking into that for you. Six, nine, eight, seven five. Okay. Thank you.\"\n",
    "\n",
    "# Split call 2 channel 2 paid text into sentences and score each\n",
    "for sentence in sent_tokenize(call_2_channel_2_paid_api_text):\n",
    "    print(sentence)\n",
    "    print(sid.polarity_scores(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Transcribe call 4 channel 2\n",
    "call_4_channel_2_text = transcribe_audio(\"./ex4_call_4_channel_2_formatted.wav\")\n",
    "\n",
    "# Create a spaCy language model instance\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc with call 4 channel 2 text\n",
    "doc = nlp(call_4_channel_2_text)\n",
    "\n",
    "# Check the type\n",
    "print(type(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how 0\n",
      "I 4\n",
      "can 6\n",
      "you 10\n",
      "my 14\n",
      "name 17\n",
      "is 22\n",
      "N 25\n",
      "and 27\n",
      "just 31\n",
      "purchased 36\n",
      "a 46\n",
      "smart 48\n",
      "point 54\n",
      "from 60\n",
      "you 65\n",
      "and 69\n",
      "I 73\n",
      "am 75\n",
      "very 78\n",
      "happy 83\n",
      "with 89\n",
      "the 94\n",
      "product 98\n",
      "I 106\n",
      "would 108\n",
      "like 114\n",
      "to 119\n",
      "order 122\n",
      "another 128\n",
      "one 136\n",
      "for 140\n",
      "my 144\n",
      "friend 147\n",
      "he 154\n",
      "lives 157\n",
      "in 163\n",
      "Sydney 166\n",
      "and 173\n",
      "have 177\n",
      "to 182\n",
      "leave 185\n",
      "it 191\n",
      "I 194\n",
      "am 196\n",
      "pretty 199\n",
      "sure 206\n",
      "it 211\n",
      "'s 213\n",
      "model 216\n",
      "315 222\n",
      "I 226\n",
      "can 228\n",
      "check 232\n",
      "that 238\n",
      "for 243\n",
      "you 247\n",
      "and 251\n",
      "I 255\n",
      "'ll 256\n",
      "give 260\n",
      "you 265\n",
      "my 269\n",
      "details 272\n",
      "thank 280\n",
      "you 286\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc with call 4 channel 2 text\n",
    "doc = nlp(call_4_channel_2_text)\n",
    "\n",
    "# Show tokens in doc\n",
    "for token in doc:\n",
    "    print(token.text, token.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how I can you my name is N and just purchased a smart point from you and I am very happy with the product I would like to order another one for my friend he lives in Sydney and have to leave it I am pretty sure it's model 315\n",
      "I can check that for you and I'll give you my details thank you\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc with call 4 channel 2 text\n",
    "doc = nlp(call_4_channel_2_text)\n",
    "\n",
    "# Show sentences in doc\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N GPE\n",
      "Sydney GPE\n",
      "315 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a spaCy doc with call 4 channel 2 text\n",
    "doc = nlp(call_4_channel_2_text)\n",
    "\n",
    "# Show named entities and their labels\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'ruler' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, en.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\94-Spoken Language Processing in Python\\04-Processing text transcribed from spoken language.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ruler\u001b[39m.\u001b[39madd_patterns([{\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPRODUCT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpattern\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msmartphone\u001b[39m\u001b[39m\"\u001b[39m}])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Update existing pipeline\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m nlp\u001b[39m.\u001b[39;49madd_pipe(\u001b[39m'\u001b[39;49m\u001b[39mruler\u001b[39;49m\u001b[39m'\u001b[39;49m, before\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mner\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Test new entity\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X23sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m entity \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39ments:\n",
      "File \u001b[1;32mc:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:821\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    817\u001b[0m     pipe_component, factory_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_pipe_from_source(\n\u001b[0;32m    818\u001b[0m         factory_name, source, name\u001b[39m=\u001b[39mname\n\u001b[0;32m    819\u001b[0m     )\n\u001b[0;32m    820\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 821\u001b[0m     pipe_component \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_pipe(\n\u001b[0;32m    822\u001b[0m         factory_name,\n\u001b[0;32m    823\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    824\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    825\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[0;32m    826\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    827\u001b[0m     )\n\u001b[0;32m    828\u001b[0m pipe_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[0;32m    829\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_meta[name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[1;32mc:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:690\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[1;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_factory(factory_name):\n\u001b[0;32m    683\u001b[0m     err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE002\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    684\u001b[0m         name\u001b[39m=\u001b[39mfactory_name,\n\u001b[0;32m    685\u001b[0m         opts\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactory_names),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    688\u001b[0m         lang_code\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang,\n\u001b[0;32m    689\u001b[0m     )\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[0;32m    691\u001b[0m pipe_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n\u001b[0;32m    692\u001b[0m \u001b[39m# This is unideal, but the alternative would mean you always need to\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[39m# specify the full config settings, which is not really viable.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: [E002] Can't find factory for 'ruler' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, en.lemmatizer"
     ]
    }
   ],
   "source": [
    "# Import EntityRuler class\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Create EntityRuler instance\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "# Define pattern for new entity\n",
    "ruler.add_patterns([{\"label\": \"PRODUCT\", \"pattern\": \"smartphone\"}])\n",
    "\n",
    "# Update existing pipeline\n",
    "nlp.add_pipe('ruler', before=\"ner\")\n",
    "\n",
    "# Test new entity\n",
    "for entity in doc.ents:\n",
    "  print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'ruler' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, en.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\94-Spoken Language Processing in Python\\04-Processing text transcribed from spoken language.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ruler\u001b[39m.\u001b[39madd_patterns([{\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPRODUCT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpattern\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msmartphone\u001b[39m\u001b[39m\"\u001b[39m}])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Add ruler to pipeline\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m nlp\u001b[39m.\u001b[39;49madd_pipe(\u001b[39m'\u001b[39;49m\u001b[39mruler\u001b[39;49m\u001b[39m'\u001b[39;49m, before\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mner\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Test new entity\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m entity \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39ments:\n",
      "File \u001b[1;32mc:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:821\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    817\u001b[0m     pipe_component, factory_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_pipe_from_source(\n\u001b[0;32m    818\u001b[0m         factory_name, source, name\u001b[39m=\u001b[39mname\n\u001b[0;32m    819\u001b[0m     )\n\u001b[0;32m    820\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 821\u001b[0m     pipe_component \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_pipe(\n\u001b[0;32m    822\u001b[0m         factory_name,\n\u001b[0;32m    823\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m    824\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    825\u001b[0m         raw_config\u001b[39m=\u001b[39;49mraw_config,\n\u001b[0;32m    826\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m    827\u001b[0m     )\n\u001b[0;32m    828\u001b[0m pipe_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_pipe_index(before, after, first, last)\n\u001b[0;32m    829\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_meta[name] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n",
      "File \u001b[1;32mc:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:690\u001b[0m, in \u001b[0;36mLanguage.create_pipe\u001b[1;34m(self, factory_name, name, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_factory(factory_name):\n\u001b[0;32m    683\u001b[0m     err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE002\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    684\u001b[0m         name\u001b[39m=\u001b[39mfactory_name,\n\u001b[0;32m    685\u001b[0m         opts\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactory_names),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    688\u001b[0m         lang_code\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlang,\n\u001b[0;32m    689\u001b[0m     )\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[0;32m    691\u001b[0m pipe_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_factory_meta(factory_name)\n\u001b[0;32m    692\u001b[0m \u001b[39m# This is unideal, but the alternative would mean you always need to\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[39m# specify the full config settings, which is not really viable.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: [E002] Can't find factory for 'ruler' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, entity_ruler, tagger, morphologizer, ner, beam_ner, senter, sentencizer, spancat, spancat_singlelabel, span_finder, future_entity_ruler, span_ruler, textcat, textcat_multilabel, en.lemmatizer"
     ]
    }
   ],
   "source": [
    "# Import EntityRuler class\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Create EntityRuler instance\n",
    "ruler = EntityRuler(nlp)\n",
    "\n",
    "# Define pattern for new entity\n",
    "ruler.add_patterns([{\"label\": \"PRODUCT\", \"pattern\": \"smartphone\"}])\n",
    "\n",
    "# Add ruler to pipeline\n",
    "nlp.add_pipe(ruler, before=\"ner\")\n",
    "\n",
    "# Test new entity\n",
    "for entity in doc.ents:\n",
    "  print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.vocab.Vocab' object has no attribute 'vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\94-Spoken Language Processing in Python\\04-Processing text transcribed from spoken language.ipynb Cell 20\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspacy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpipeline\u001b[39;00m \u001b[39mimport\u001b[39;00m EntityRuler\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Instantiate Ruler component\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ruler \u001b[39m=\u001b[39m EntityRuler(nlp\u001b[39m.\u001b[39;49mvocab)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Define patterns\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m patterns \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mPRODUCT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpattern\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msmartphone\u001b[39m\u001b[39m\"\u001b[39m}]\n",
      "File \u001b[1;32mc:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\pipeline\\entityruler.py:130\u001b[0m, in \u001b[0;36mEntityRuler.__init__\u001b[1;34m(self, nlp, name, phrase_matcher_attr, matcher_fuzzy_compare, validate, overwrite_ents, ent_id_sep, patterns, scorer)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate \u001b[39m=\u001b[39m validate\n\u001b[0;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatcher_fuzzy_compare \u001b[39m=\u001b[39m matcher_fuzzy_compare\n\u001b[0;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatcher \u001b[39m=\u001b[39m Matcher(\n\u001b[1;32m--> 130\u001b[0m     nlp\u001b[39m.\u001b[39;49mvocab, validate\u001b[39m=\u001b[39mvalidate, fuzzy_compare\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmatcher_fuzzy_compare\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mphrase_matcher_attr \u001b[39m=\u001b[39m phrase_matcher_attr\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mphrase_matcher \u001b[39m=\u001b[39m PhraseMatcher(\n\u001b[0;32m    134\u001b[0m     nlp\u001b[39m.\u001b[39mvocab, attr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mphrase_matcher_attr, validate\u001b[39m=\u001b[39mvalidate\n\u001b[0;32m    135\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.vocab.Vocab' object has no attribute 'vocab'"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Instantiate Ruler component\n",
    "ruler = EntityRuler(nlp.vocab)\n",
    "\n",
    "# Define patterns\n",
    "patterns = [{\"label\": \"PRODUCT\", \"pattern\": \"smartphone\"}]\n",
    "\n",
    "# Add patterns to ruler\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "# Add ruler to pipeline before NER component\n",
    "nlp.add_pipe(ruler, before=\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ./ex3-static-help-with-account.mp3 to .wav...\n",
      "Converting ./ex3-static-help-with-account.mp3 to .wav...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pre_purchase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\94-Spoken Language Processing in Python\\04-Processing text transcribed from spoken language.ipynb Cell 21\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     convert_to_wav(file)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Convert pre purchase\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m pre_purchase:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConverting \u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m to .wav...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     convert_to_wav(file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pre_purchase' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert post purchase\n",
    "import os\n",
    "post_purchase = ['./ex3-static-help-with-account.mp3']\n",
    "\n",
    "for file in post_purchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    convert_to_wav(file)\n",
    "\n",
    "# Convert pre purchase\n",
    "for file in pre_purchase:\n",
    "    print(f\"Converting {file} to .wav...\")\n",
    "    convert_to_wav(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing file: .wav...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"I can't really login to it at all I think I forgot my password and email reset is not working so the sound you can help me out my account not to be great\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_text_list(folder):\n",
    "  # Create empty list\n",
    "  text_list = []\n",
    "  \n",
    "  # Go through each file\n",
    "  for file in folder:\n",
    "    # Make sure the file is .wav\n",
    "    if file.endswith(\".wav\"):\n",
    "      print(f\"Transcribing file: {file}...\")\n",
    "      \n",
    "      # Transcribe audio and append text to list\n",
    "      text_list.append(transcribe_audio(file))\n",
    "  return text_list\n",
    "folder = ['.wav']\n",
    "create_text_list(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing file: .wav...\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Transcribe post and pre purchase text\n",
    "post_purchase_text = create_text_list(create_text_list(folder))\n",
    "# pre_purchase_text = create_text_list(pre_purchase_wav_files)\n",
    "\n",
    "# Inspect the first transcription of post purchase\n",
    "print(post_purchase_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Make dataframes with the text\n",
    "post_purchase_df = pd.DataFrame({\"label\": \"post_purchase\",\n",
    "                                 \"text\": post_purchase_text})\n",
    "pre_purchase_df = pd.DataFrame({\"label\": \"pre_purchase\",\n",
    "                                \"text\": pre_purchase_text})\n",
    "\n",
    "# Combine DataFrames\n",
    "df = pd.concat([post_purchase_df, pre_purchase_df])\n",
    "\n",
    "# Print the combined DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\94-Spoken Language Processing in Python\\04-Processing text transcribed from spoken language.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Build the text_classifier as an sklearn pipeline\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m text_classifier \u001b[39m=\u001b[39m Pipeline([\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mvectorizer\u001b[39m\u001b[39m'\u001b[39m, CountVectorizer()),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mtfidf\u001b[39m\u001b[39m'\u001b[39m, TfidfTransformer()),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m, MultinomialNB()),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Fit the classifier pipeline on the training data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/94-Spoken%20Language%20Processing%20in%20Python/04-Processing%20text%20transcribed%20from%20spoken%20language.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m text_classifier\u001b[39m.\u001b[39mfit(train_df\u001b[39m.\u001b[39mtext, train_df\u001b[39m.\u001b[39mlabel)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "# Build the text_classifier as an sklearn pipeline\n",
    "text_classifier = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Fit the classifier pipeline on the training data\n",
    "text_classifier.fit(train_df.text, train_df.label)\n",
    "\n",
    "# Evaluate the MultinomialNB model\n",
    "predicted = text_classifier.predict(test_df.text)\n",
    "accuracy = 100 * np.mean(predicted == test_df.label)\n",
    "print(f'The model is {accuracy}% accurate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
