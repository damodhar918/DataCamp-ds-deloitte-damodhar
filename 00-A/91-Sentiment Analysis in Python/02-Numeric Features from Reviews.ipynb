{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 1 1 1 1 2 1]]\n"
     ]
    }
   ],
   "source": [
    "# Import the required function\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "annak = ['Happy families are all alike;', 'every unhappy family is unhappy in its own way']\n",
    "\n",
    "# Build the vectorizer and fit it\n",
    "anna_vect = CountVectorizer()\n",
    "anna_vect.fit(annak)\n",
    "\n",
    "# Create the bow representation\n",
    "anna_bow = anna_vect.transform(annak)\n",
    "\n",
    "# Print the bag-of-words result \n",
    "print(anna_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   about  after  all  also  an  and  any  are  as  at  ...  well  were  what  \\\n",
      "0      0      0    0     0   0    1    0    0   2   0  ...     0     0     0   \n",
      "1      0      0    3     1   1   11    0    3   3   4  ...     0     0     1   \n",
      "2      0      1    0     0   1    7    0    1   2   1  ...     0     0     0   \n",
      "3      0      0    0     0   2    1    0    1   2   2  ...     1     0     0   \n",
      "4      0      0    3     0   0    8    0    3   1   0  ...     2     1     0   \n",
      "\n",
      "   when  which  who  will  with  would  you  \n",
      "0     0      0    0     0     1      1    0  \n",
      "1     1      2    0     2     7      2    3  \n",
      "2     0      0    0     0     2      0    0  \n",
      "3     0      0    1     0     0      0    1  \n",
      "4     1      1    0     0     2      0    0  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "reviews = pd.read_csv('./IMDB_sample.csv', index_col=0)\n",
    "# Build the vectorizer, specify max features \n",
    "vect = CountVectorizer(max_features=100)\n",
    "# Fit the vectorizer\n",
    "vect.fit(reviews.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(reviews.review)\n",
    "\n",
    "\n",
    "# Create the bow representation\n",
    "# X_df=pd.DataFrame(X_review.todense(), columns=vect.get_feature_names())\n",
    "X_df=pd.DataFrame(X_review.todense(), columns=vect.get_feature_names_out())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  00 am  00 and  00 at  00 back  00 bin  00 but  00 doc  00 dollars  \\\n",
      "0   0      0       0      0        0       0       0       0           0   \n",
      "1   0      0       0      0        0       0       0       0           0   \n",
      "2   0      0       0      0        0       0       0       0           0   \n",
      "3   0      0       0      0        0       0       0       0           0   \n",
      "4   0      0       0      0        0       0       0       0           0   \n",
      "\n",
      "   00 for  ...  zx81  zx81 the  zy  zy melvyn  zzzzzzzzzzzz  zzzzzzzzzzzz br  \\\n",
      "0       0  ...     0         0   0          0             0                0   \n",
      "1       0  ...     0         0   0          0             0                0   \n",
      "2       0  ...     0         0   0          0             0                0   \n",
      "3       0  ...     0         0   0          0             0                0   \n",
      "4       0  ...     0         0   0          0             0                0   \n",
      "\n",
      "   zzzzzzzzzzzzz  â½  â½ hour  â½ out  \n",
      "0              0   0        0       0  \n",
      "1              0   0        0       0  \n",
      "2              0   0        0       0  \n",
      "3              0   0        0       0  \n",
      "4              0   0        0       0  \n",
      "\n",
      "[5 rows x 631043 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "\n",
    "# Build the vectorizer, specify token sequence and fit\n",
    "vect = CountVectorizer(ngram_range=(1,2))\n",
    "vect.fit(reviews.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(reviews.review)\n",
    "\n",
    "# Create the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names_out())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   about  after  all  also  an  and  any  are  as  at  ...  well  were  what  \\\n",
      "0      0      0    0     0   0    1    0    0   2   0  ...     0     0     0   \n",
      "1      0      0    3     1   1   11    0    3   3   4  ...     0     0     1   \n",
      "2      0      1    0     0   1    7    0    1   2   1  ...     0     0     0   \n",
      "3      0      0    0     0   2    1    0    1   2   2  ...     1     0     0   \n",
      "4      0      0    3     0   0    8    0    3   1   0  ...     2     1     0   \n",
      "\n",
      "   when  which  who  will  with  would  you  \n",
      "0     0      0    0     0     1      1    0  \n",
      "1     1      2    0     2     7      2    3  \n",
      "2     0      0    0     0     2      0    0  \n",
      "3     0      0    1     0     0      0    1  \n",
      "4     1      1    0     0     2      0    0  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "movies = pd.read_csv('./IMDB_sample.csv', index_col=0)\n",
    "# Build the vectorizer, specify size of vocabulary and fit\n",
    "vect = CountVectorizer(max_features=100)\n",
    "vect.fit(movies.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(movies.review)\n",
    "# Create the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names_out())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  000  000s  007  0080  0083  0093638  00am  00pm  00s  ...  zukovic  \\\n",
      "0   0    0     0    0     0     0        0     0     0    0  ...        0   \n",
      "1   0    0     0    0     0     0        0     0     0    0  ...        0   \n",
      "2   0    0     0    0     0     0        0     0     0    0  ...        0   \n",
      "3   0    0     0    0     0     0        0     0     0    0  ...        0   \n",
      "4   0    0     0    0     0     0        0     0     0    0  ...        0   \n",
      "\n",
      "   zulu  zuniga  zvyagvatsev  zwick  zx81  zy  zzzzzzzzzzzz  zzzzzzzzzzzzz  â½  \n",
      "0     0       0            0      0     0   0             0              0   0  \n",
      "1     0       0            0      0     0   0             0              0   0  \n",
      "2     0       0            0      0     0   0             0              0   0  \n",
      "3     0       0            0      0     0   0             0              0   0  \n",
      "4     0       0            0      0     0   0             0              0   0  \n",
      "\n",
      "[5 rows x 45055 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "# Build and fit the vectorizer\n",
    "vect = CountVectorizer(max_df=200)\n",
    "vect.fit(movies.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(movies.review)\n",
    "# Create the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names_out())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   000  10  100  11  12  13  14  15  1950  1980  ...  york  you  young  \\\n",
      "0    0   0    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
      "1    0   1    0   0   0   0   0   0     0     0  ...     0    3      0   \n",
      "2    0   0    0   0   0   0   0   0     0     0  ...     0    0      1   \n",
      "3    0   0    0   0   0   0   0   0     0     0  ...     0    1      1   \n",
      "4    0   1    0   0   0   0   0   0     0     0  ...     0    0      0   \n",
      "\n",
      "   younger  your  yourself  youth  zero  zombie  zombies  \n",
      "0        0     0         0      0     0       0        1  \n",
      "1        0     2         0      0     0       0        0  \n",
      "2        0     0         0      0     0       0        0  \n",
      "3        0     0         0      0     0       0        0  \n",
      "4        1     0         0      0     0       0        0  \n",
      "\n",
      "[5 rows x 2552 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "# Build and fit the vectorizer\n",
    "vect = CountVectorizer(min_df=50)\n",
    "vect.fit(movies.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(movies.review)\n",
    "# Create the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names_out())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   able to  about it  about this  acting and  acting is  acting was  \\\n",
      "0        0         0           0           0          0           0   \n",
      "1        0         0           0           0          0           0   \n",
      "2        0         0           0           0          0           0   \n",
      "3        0         0           0           0          0           0   \n",
      "4        0         0           0           0          0           0   \n",
      "\n",
      "   actors and  after all  after the  again and  ...  you ll  you might  \\\n",
      "0           0          0          0          0  ...       0          0   \n",
      "1           0          0          0          0  ...       0          0   \n",
      "2           0          0          0          0  ...       0          0   \n",
      "3           0          0          0          0  ...       0          0   \n",
      "4           0          0          0          0  ...       0          0   \n",
      "\n",
      "   you see  you think  you to  you ve  you want  you will  you would  \\\n",
      "0        0          0       0       0         0         0          0   \n",
      "1        0          0       0       0         0         0          0   \n",
      "2        0          0       0       0         0         0          0   \n",
      "3        0          0       0       0         0         0          0   \n",
      "4        0          0       0       0         0         0          0   \n",
      "\n",
      "   your time  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n",
      "\n",
      "[5 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "# Build the vectorizer, specify max features and fit\n",
    "vect = CountVectorizer(max_features=1000, ngram_range=(2, 2), max_df=500)\n",
    "vect.fit(reviews.review)\n",
    "\n",
    "# Transform the review\n",
    "X_review = vect.transform(reviews.review)\n",
    "\n",
    "# Create a DataFrame from the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names_out())\n",
    "print(X_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Never', 'forget', 'what', 'you', 'are', ',', 'for', 'surely', 'the', 'world', 'will', 'not', '.', 'Make', 'it', 'your', 'strength', '.', 'Then', 'it', 'can', 'never', 'be', 'your', 'weakness', '.', 'Armour', 'yourself', 'in', 'it', ',', 'and', 'it', 'will', 'never', 'be', 'used', 'to', 'hurt', 'you', '.']\n"
     ]
    }
   ],
   "source": [
    "# Import the required function\n",
    "from nltk import word_tokenize\n",
    "GoT = 'Never forget what you are, for surely the world will not. Make it your strength. Then it can never be your weakness. Armour yourself in it, and it will never be used to hurt you.'\n",
    "\n",
    "# Transform the GoT string to word tokens\n",
    "print(word_tokenize(GoT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avengers = [\"Cause if we can't protect the Earth, you can be d*** sure we'll avenge it\",\n",
    " 'There was an idea to bring together a group of remarkable people, to see if we could become something more',\n",
    " \"These guys come from legend, Captain. They're basically Gods.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Cause', 'if', 'we', 'ca', \"n't\", 'protect', 'the', 'Earth', ',', 'you', 'can', 'be', 'd', '*', '*', '*', 'sure', 'we', \"'ll\", 'avenge', 'it'], ['There', 'was', 'an', 'idea', 'to', 'bring', 'together', 'a', 'group', 'of', 'remarkable', 'people', ',', 'to', 'see', 'if', 'we', 'could', 'become', 'something', 'more'], ['These', 'guys', 'come', 'from', 'legend', ',', 'Captain', '.', 'They', \"'re\", 'basically', 'Gods', '.']]\n"
     ]
    }
   ],
   "source": [
    "# Import the word tokenizing function\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Tokenize each item in the avengers \n",
    "tokens_avengers = [word_tokenize(item) for item in avengers]\n",
    "\n",
    "print(tokens_avengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'short', 'spoof', 'can', 'be', 'found', 'on', 'Elite', \"'s\", 'Millennium', 'Edition', 'DVD', 'of', '``', 'Night', 'of', 'the', 'Living', 'Dead', \"''\", '.', 'Good', 'thing', 'to', 'as', 'I', 'would', 'have', 'never', 'went', 'even', 'a', 'tad', 'out', 'of', 'my', 'way', 'to', 'see', 'it.Replacing', 'zombies', 'with', 'bread', 'sounds', 'just', 'like', 'silly', 'harmless', 'fun', 'on', 'paper', '.', 'In', 'execution', ',', 'it', \"'s\", 'a', 'different', 'matter', '.', 'This', 'short', 'did', \"n't\", 'even', 'elicit', 'a', 'chuckle', 'from', 'me', '.', 'I', 'really', 'never', 'thought', 'I', \"'d\", 'say', 'this', ',', 'but', '``', 'Night', 'of', 'the', 'Day', 'of', 'the', 'Dawn', 'of', 'the', 'Son', 'of', 'the', 'Bride', 'of', 'the', 'Return', 'of', 'the', 'Revenge', 'of', 'the', 'Terror', 'of', 'the', 'Attack', 'of', 'the', 'Evil', ',', 'Mutant', ',', 'Alien', ',', 'Flesh', 'Eating', ',', 'Hellbound', ',', 'Zombified', 'Living', 'Dead', 'Part', '2', ':', 'In', 'Shocking', '2-D', \"''\", 'was', 'a', 'VERY', 'better', 'parody', 'and', 'not', 'nearly', 'as', 'lame', 'or', 'boring.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'My', 'Grade', ':', 'F']\n"
     ]
    }
   ],
   "source": [
    "# Import the needed packages\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Tokenize each item in the review column\n",
    "word_tokens = [word_tokenize(review) for review in reviews.review]\n",
    "\n",
    "# Print out the first item of the word_tokens list\n",
    "print(word_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the length of the reviews\n",
    "len_tokens = []\n",
    "\n",
    "# Iterate over the word_tokens list and determine the length of each item\n",
    "for i in range(len(word_tokens)):\n",
    "     len_tokens.append(len(word_tokens[i]))\n",
    "\n",
    "# Create a new feature for the lengh of each review\n",
    "reviews['n_words'] = len_tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fr:0.9999973502360225]\n"
     ]
    }
   ],
   "source": [
    "# Import the language detection function and package\n",
    "from langdetect import detect_langs\n",
    "foreign = \"L'histoire rendu était fidèle, excellent, et grande.\"\n",
    "\n",
    "# Detect the language of the foreign string\n",
    "print(detect_langs(foreign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The detected languages are:  [[fr:0.9999980535331878], [es:0.999994221935394], [en:0.9999966511265294]]\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect_langs\n",
    "\n",
    "languages = []\n",
    "sentences = [\"L'histoire rendu était fidèle, excellent, et grande.\",\n",
    " 'Excelente muy recomendable.',\n",
    " 'It had a leak from day one but the return and exchange process was very quick.']\n",
    "\n",
    "# Loop over the sentences in the list and detect their language\n",
    "for sentence in sentences:\n",
    "    languages.append(detect_langs(sentence))\n",
    "    \n",
    "print('The detected languages are: ', languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_english_reviews = pd.DataFrame({'score': {1249: 1,\n",
    "  1259: 1,\n",
    "  1260: 1,\n",
    "  1261: 1,\n",
    "  1639: 1,\n",
    "  1745: 1,\n",
    "  2316: 1,\n",
    "  2486: 1,\n",
    "  2760: 0,\n",
    "  2903: 1,\n",
    "  2908: 0,\n",
    "  3318: 1,\n",
    "  3694: 0,\n",
    "  4820: 1,\n",
    "  4914: 0,\n",
    "  5720: 1,\n",
    "  5875: 1,\n",
    "  5901: 1,\n",
    "  6234: 1,\n",
    "  6631: 0,\n",
    "  7078: 1,\n",
    "  7307: 0,\n",
    "  7888: 0,\n",
    "  7983: 1,\n",
    "  8018: 1,\n",
    "  8340: 1,\n",
    "  9265: 1,\n",
    "  9422: 0,\n",
    "  9624: 0},\n",
    " 'review': {1249: ' Il grande ritorno!: E\\' dai tempi del tour di \"empire\" che non vedevo i queensryche così in gran forma, questo dvd per me è il migliore di tutta la loro carriera, e la consacrazione di una band, dopo questo dvd si può tranquillamente dire che i queenssryche sono entrati nella storia del grande rock come i Deep purple, led zeppelin e thin lizzy negli anni settanta.I queensryche sempre si sono distinti dagli altri gruppi del loro genere, Geoff Tate è uno dei più importanti vocalists di tutti i tempi.Questo dvd è musica e teatro, la collaborazione più stretta con Pamela Moore rende questo dvd imperdibile.Una sola nota negativa, purtroppo nella composizione della seconda parte si sente l\\'assenza di Chris De Garmo,Mike Stone è un grande chitarrista, ma Chris De Garmo per me era fondamentale per la band, hanno perso la parte più melodoca, che era a mio parere molto importante in questo gruppo!\\r\\n',\n",
    "  1259: ' La reencarnación vista por un científico: El primer libro del Dr. Weiss sigue siendo un gran libro para todos aquellos a quienes les inquieta el tema de la reencarnación, así no crean en ella.\\r\\n',\n",
    "  1260: ' Excelente Libro / Amazing book!!: Este libro ha sido uno de los mejores libros que he leido, soy adicta a la lectura y este libro me ayudo en muchas formas. Te ensena a analizar muchas cosas, a comprender otras con respecto a la vida y te lleva a tener una mente mas abierta cuando por ejemplo te pone a dudar si hay mas vidas ya que en algunas religiones eso es inconcebible.This book is one of the best books I have ever read, It makes you think and wonder about past life especially if you do not believe in that. I truly recommend this book.\\r\\n',\n",
    "  1261: ' Magnifico libro: Brian Weiss ha dejado una magnifica guia para quienes no tienen mucha informacion acerca del Hipnotismo, La historia de Katerine es tan impresionante que podria ayudar a culquier persona que se ha hecho la pregunta mas de una vez sobre la continuidad de la vida.\\r\\n',\n",
    "  1639: ' El libro mas completo que existe para nosotras,: las m,ujeres embarazadas o por embarazarnos...LO ABARCA TODO, DESDE LA CONCEPCION HASTA QUE EL BEBE CUMPLE UN AÑO...Dulce, sabio y ameno...\\r\\n',\n",
    "  1745: ' Excelente!: Una excelente guía para todos aquellos que deseen concer más aobre el vino y su mundo. De forma amena y sencilla explica los principales conceptos y orienta sobre temas básicos como la elección del vino corecto, principales tipos de vino, cómo comprar vino en restaurantes o tiendas, etc.\\r\\n',\n",
    "  2316: ' Nightwish is unique and rocks for eva: Moi to you all,Nightwish est vraiment le plus cool des bands. Unqiue pis des tounes supers orginales, ca ma faite découvrir le métal pis aucune autre band ma faite vribrer comme eux. À tous le monde cest un must buy.\\r\\n',\n",
    "  2486: ' Palabras de aliento para tu caminar con Dios: Una vez mas Charles Swindoll llega al corazón del cristiano como tu y como yo. Nos alienta y nos da enseñanza de como enfrentar nuestros Gigantes, reconocer su origen y escudriñar en nuestro corazón para dar con esas espinas que han estado clavadas por mucho tiempo e impide que nuestro caminar con Dios sea firme. Prácticos y profundos principios para ayudarnos a ser mejores en nuestra casa, trabajo y en la iglesia.\\r\\n',\n",
    "  2760: \" Completement nul: Fait sur commande et ennuyant a mourir, cette album est tout a fait parfait pour s'endormir...nul!\\r\\n\",\n",
    "  2903: ' fabuloso: mil gracias por el producto fabuloso recomiendo a este vendedor todo llego en perfectas condiciones excelentesaludos espero seguir contando con ustedes\\r\\n',\n",
    "  2908: ' Geh: Blah blah, sexy girl, blah blah, fighting robots, blah blah, cliche action lines, blah blah, talking robots, blah blah blah.\\r\\n',\n",
    "  3318: ' Excelentes botas.. excelentes boots: Excelente producto, quedo muy satisfecho con el producto y con Amazon, por la puntualidad en la entrega,la calidad del producto, zapatos muy comodos, resistentes. Excelente muy recomendable.\\r\\n',\n",
    "  3694: \" Why not Spanish ???: Alguien me puede decir porque la serie Three's Company no viene ni con audio ni con subtitulos en ESPAÑOL.Esta serie fue vista a nivel mundial, si casi todas las series que salen en dvd con varios idiomas que paso con esta si es una de las mejores de todos los tiempos.Una comedia excelente y unica deberian de haber tomado en cuenta aca en mi pais la dieron con audio en español, donde quedo eso ???.Ahora si viene en audio ESPAÑOL o por lo menos subtitulo pido mil disculpas pero no dice por ningun lado en la descripcion del producto.SALUDOS\\r\\n\",\n",
    "  4820: ' La mejor película de Moore: A mi juicio, esta es la mejor comedia de Dudley Moore.El reparto es excelente.Realmente la recomiendo.\\r\\n',\n",
    "  4914: \" De la poudre aux yeux: J'ai acheté un Sansa View 16gB pour $200 CAD il y a deux ans et demie à peine, et la batterie vient de mourrir. L'estimation pour la réparation et le remplecement de la batteire est de $80 minimum, vous voyez le topo? Malgré son excellente sonorité, je ne recommande pas cet appareil, difficile à comprendre, parfois il gèle... à éviter!\\r\\n\",\n",
    "  5720: \" C'est magnifique! il y a du vrai dans ce qui'l dit.: Il y a des temps que Mr. Coello nous avons donné une histoire de honor et de mystère. Cet histoire étre publié en different langues. Je l'ai li en anglais et en franais seulement. La histoire rendu étai fidèle, excellent, et grand. Il raconte du rve de un bon garon que cherche le monde pour trouver un inconnu trésor. Il l'a réussi...mais... Je suis certain qui il a trouvé deux trésors... voila! vous devez lire la histoire maintenant pour découvrir le mystére; s'il vous plait.\\r\\n\",\n",
    "  5875: ' Erreur: \"Les Triplettes de Belleville\" n\\'a pas reu le Jutra de la meilleure bande sonore, puisqu\\'il n\\'était pas en nomination. \"Gaz Bar Blues\" l\\'a remporté.\\r\\n',\n",
    "  5901: ' Buen cargador: Product very good, I am of Venezuela the exelente product thanks(Producto muy buenos, soy de venezuela el producto exelente gracias)\\r\\n',\n",
    "  6234: ' 5+ stars. LO MEJOR DE LO QUE HE LEIDO EN MI VIDA.: Un resúmen:El clan del oso cavernario: EXCELENTE, INSPIRADOR.Un libro para leer y releer, es como un libro de superación personal, pero sin los aburridos consejos sabiondos de los autores, ni las falsas promesas de los nuevos autores llamados \"new age\". DEBE LEERLO, Y POR FAVOR, NO LO PRESTE.....!El valle de los caballos: BUENA SECUELA, RECOMENDABLE.Los cazadores del mamut: SOLO PARA FANS.El libro de los viajes (\"Plains\"): REPETITIVO, LENTO Y ABURRIDO EN DOS TERCERAS PARTES (LA\\'ÚLTIMA PARTE, COMO EN \"cazadores\", PARA FANS).....LA ESPERANZA....\"The Shelter of stone\"...donde los que admiramos a Ayla, esperamos reencontrarnos con ella...\\r\\n',\n",
    "  6631: ' certains bugs viennent tout gacher: le jeu est bon mais comporte des bugs sur xbox live , les statistiques ne sont pas compiliees correctement sur xbox live. on perd la connection de temps a autre et une deconnection compte parfois pour une defaite... bon jeu a 1 joueur mais pas fort sur le live...\\r\\n',\n",
    "  7078: ' Variedad: Bueno tener este album debido a su sonido peculiar, algunas de sus canciones hasta fueron programadas aca en la radio en Guanatos...es + el Kala (Rostros Ocultos) se encargó de hacer un cover el cual fue un exito en español - con los Smithreens nunca lo fue - (\"Tiempo de Cambiar\" o \"Something New\"). Saludos de neta. Mork\\r\\n',\n",
    "  7307: \" Disappointing. Does not deserve to be a 'classic': Length:: 3:49 MinsFahrenheit 451Fahrenheit 451: A Novel\\r\\n\",\n",
    "  7888: ' Ich weiß ja nicht !: Also ich finde es ja toll, dass ein deutscher Film in den USA so gut ankommt, aber ich habe ihn bei uns in Deutschland im Kino gesehen und dachte mir \"wie lange rennt die denn noch\" und \"warum rennt die schon wieder\". Mein Freundin fand den Film aber echt klasse. Von den vier Leuten die wir waren gibt einer 5 Sterne, 2 geben drei Sterne und ich gebe dem Film 2 Sterne. Würde ihn mir aber niemals auf DVD oder Video kaufen.\\r\\n',\n",
    "  7983: ' 1F4T: Cet album est chanté vraiment bien. Jean-Jacques et les autres \"types\" ont bien fait! Les chansons sont pas forte en vocales, mais les paroles sont très très émouvantes. Surtout \"Rien n\\'est vraiment fini\". \"Je Lui Dirai\", c\\'est le fun. Son premier 45 \"Tout L\\'Or Des Hommes\" place le feeling pour le reste de l\\'album. C\\'est super, a! Achète l\\'album! a vaut l\\'argent!\\r\\n',\n",
    "  8018: ' Exelente eleccion: Los mejores zapatos de futbol que he comprado en mi vida, funcionan perfecto para cesped artifical, cesped natural y piso duro.Lo recomiendo 100%\\r\\n',\n",
    "  8340: ' Jean de Florette et Manon des sources: bien aimé ses deux films et aimerais les acheté si vous pouvié me les faires parvenire. Jean de Florette et Manon des sources en dvd. merci a vous.attend une réponse de vous.\\r\\n',\n",
    "  9265: \" Excelente: Manu es una de los mejores cantantes del Operacion Triunfo.Aunque la musica es un poco 'easy listening', este CD es su premera y Manu la hace muy bien y no se falta su voz. Me encanta este chico y creo que el va a hacer mucho mas.\\r\\n\",\n",
    "  9422: ' DVD CON PROBLEMAS: ESTE DVD LLEGO EN BUEN TIEMPO. SIN EMBARGO, SE FREEZA EN LA CANCION NUMERO 1 INTERPRETADA POR VICTOR MANUEL, UNA DE LAS MEJORES.\\r\\n',\n",
    "  9624: ' baaaaaadddddddd bookkkkkkk: por favor no gaste su dinero en este pesimo y mediocre libro,,lo unico que la mujer y el chino hacen es mostrar su impresionante flexibilidad,pero nada mas,,no aportan tecnicas reales ni explicaciones para llegar a ese estado.me parece mas bien que los autores lo que quieren es que la gente sepa que ellos tienen una super-flexibilidad impresionante.este es solamente un librito y nada mas,, muy,,muy pero muy mediocre\\r\\n'}}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score                                             review language\n",
      "1249      1   Il grande ritorno!: E' dai tempi del tour di ...       it\n",
      "1259      1   La reencarnación vista por un científico: El ...       es\n",
      "1260      1   Excelente Libro / Amazing book!!: Este libro ...       es\n",
      "1261      1   Magnifico libro: Brian Weiss ha dejado una ma...       es\n",
      "1639      1   El libro mas completo que existe para nosotra...       es\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect_langs\n",
    "languages = []\n",
    "\n",
    "# Loop over the rows of the dataset and append  \n",
    "for row in range(len(non_english_reviews)):\n",
    "    languages.append(detect_langs(non_english_reviews.iloc[row, 1])[0].lang)\n",
    "\n",
    "# Clean the list by splitting     \n",
    "languages = [str(lang).split(':')[0] for lang in languages]\n",
    "\n",
    "# Assign the list to a new feature \n",
    "non_english_reviews['language'] = languages\n",
    "\n",
    "print(non_english_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      score                                             review language\n",
      "1249      1   Il grande ritorno!: E' dai tempi del tour di ...       it\n",
      "1259      1   La reencarnación vista por un científico: El ...       es\n",
      "1260      1   Excelente Libro / Amazing book!!: Este libro ...       es\n",
      "1261      1   Magnifico libro: Brian Weiss ha dejado una ma...       es\n",
      "1639      1   El libro mas completo que existe para nosotra...       es\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect_langs\n",
    "languages = [] \n",
    "\n",
    "# Loop over the rows of the dataset and append  \n",
    "for row in range(len(non_english_reviews)):\n",
    "    languages.append(detect_langs(non_english_reviews.iloc[row, 1]))\n",
    "\n",
    "# Clean the list by splitting     \n",
    "languages = [str(lang).split(':')[0][1:] for lang in languages]\n",
    "\n",
    "# Assign the list to a new feature \n",
    "non_english_reviews['language'] = languages\n",
    "\n",
    "print(non_english_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
