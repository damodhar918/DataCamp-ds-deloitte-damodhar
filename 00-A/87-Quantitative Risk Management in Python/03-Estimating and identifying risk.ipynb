{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2007-01-04    0.014969\n",
       "2007-01-05   -0.010535\n",
       "2007-01-08   -0.003194\n",
       "2007-01-09    0.008812\n",
       "2007-01-10   -0.010588\n",
       "Name: Open, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossess = pd.read_csv('./GE - Historical.csv', index_col=0, parse_dates=True)\n",
    "# lossess = lossess.sort_index()\n",
    "losses = lossess.Open.pct_change().dropna()\n",
    "losses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR_95, Normal distribution:  0.050486968081522296\n",
      "Anderson-Darling test result:  AndersonResult(statistic=27.07604542415197, critical_values=array([0.573, 0.653, 0.783, 0.913, 1.086]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]), fit_result=  params: FitParams(loc=-0.0007058704271876911, scale=0.03114369508615258)\n",
      " success: True\n",
      " message: '`anderson` successfully fit the distribution to the data.')\n"
     ]
    }
   ],
   "source": [
    "# Import the Normal distribution and skewness test from scipy.stats\n",
    "from scipy.stats import norm, anderson\n",
    "\n",
    "# Fit portfolio losses to the Normal distribution\n",
    "params = norm.fit(losses)\n",
    "\n",
    "# Compute the 95% VaR from the fitted distribution, using parameter estimates\n",
    "VaR_95 = norm.ppf(0.95, *params)\n",
    "print(\"VaR_95, Normal distribution: \", VaR_95)\n",
    "\n",
    "# Test the data for Normality\n",
    "print(\"Anderson-Darling test result: \", anderson(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewtest result:  SkewtestResult(statistic=8.059974034733527, pvalue=7.631065621475823e-16)\n",
      "VaR_95 from skew-normal:  0.051961463294927915\n"
     ]
    }
   ],
   "source": [
    "# Import the skew-normal distribution and skewness test from scipy.stats\n",
    "from scipy.stats import skewnorm, skewtest\n",
    "\n",
    "# Test the data for skewness\n",
    "print(\"Skewtest result: \", skewtest(losses))\n",
    "\n",
    "# Fit the portfolio loss data to the skew-normal distribution\n",
    "params = skewnorm.fit(losses)\n",
    "\n",
    "# Compute the 95% VaR from the fitted distribution, using parameter estimates\n",
    "VaR_95 = skewnorm.ppf(0.95, *params)\n",
    "print(\"VaR_95 from skew-normal: \", VaR_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_returns = pd.read_csv('./crisis_portfolio.csv', index_col=0, parse_dates=True,date_format='%Y-%m-%d')\n",
    "asset_returns = asset_returns.pct_change().dropna()\n",
    "weights = [0.25, 0.25, 0.25, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\87-Quantitative Risk Management in Python\\03-Estimating and identifying risk.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create portfolio returns for the two sub-periods using the list of asset returns\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m portfolio_returns \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([x\u001b[39m.\u001b[39;49mdot(weights) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m asset_returns])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Derive portfolio losses from portfolio returns\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m losses \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m portfolio_returns\n",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\87-Quantitative Risk Management in Python\\03-Estimating and identifying risk.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create portfolio returns for the two sub-periods using the list of asset returns\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m portfolio_returns \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([x\u001b[39m.\u001b[39;49mdot(weights) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m asset_returns])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Derive portfolio losses from portfolio returns\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m losses \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m portfolio_returns\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'dot'"
     ]
    }
   ],
   "source": [
    "# Create portfolio returns for the two sub-periods using the list of asset returns\n",
    "portfolio_returns = np.array([x.dot(weights) for x in asset_returns])\n",
    "\n",
    "# Derive portfolio losses from portfolio returns\n",
    "losses = - portfolio_returns\n",
    "\n",
    "# Find the historical simulated VaR estimates\n",
    "VaR_95 = [np.quantile(x, 0.95) for x in losses]\n",
    "\n",
    "# Display the VaR estimates\n",
    "print(\"VaR_95, 2005-2006: \", VaR_95[0], '; VaR_95, 2007-2009: ', VaR_95[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo VaR_95 estimate:  0.0031675254576541724\n"
     ]
    }
   ],
   "source": [
    "# Initialize daily cumulative loss for the assets, across N runs\n",
    "N = 10000\n",
    "daily_loss = np.zeros((4,N))\n",
    "e_cov =  np.array([[0.00209328, 0.00114596, 0.00081893, 0.0010135 ],\n",
    "       [0.00114596, 0.00192715, 0.00097157, 0.00082012],\n",
    "       [0.00081893, 0.00097157, 0.00089666, 0.00064216],\n",
    "       [0.0010135 , 0.00082012, 0.00064216, 0.00107184]])\n",
    "total_steps = 1440\n",
    "mu = np.array([[ 0.00048534],\n",
    "       [-0.00042112],\n",
    "       [-0.00074171],\n",
    "       [-0.00056848]])\n",
    "# Create the Monte Carlo simulations for N runs\n",
    "for n in range(N):\n",
    "    # Compute simulated path of length total_steps for correlated returns \n",
    "    correlated_randomness = e_cov @ norm.rvs(size = (4,total_steps))\n",
    "    # Adjust simulated path by total_steps and mean of portfolio losses\n",
    "    steps = 1/total_steps\n",
    "    minute_losses = mu * steps + correlated_randomness * np.sqrt(steps)\n",
    "    daily_loss[:, n] = minute_losses.sum(axis=1)\n",
    "    \n",
    "# Generate the 95% VaR estimate\n",
    "losses = weights @ daily_loss\n",
    "print(\"Monte Carlo VaR_95 estimate: \", np.quantile(losses, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Citibank</th>\n",
       "      <th>Morgan Stanley</th>\n",
       "      <th>Goldman Sachs</th>\n",
       "      <th>J.P. Morgan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>03/01/2005</th>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.008747</td>\n",
       "      <td>0.003589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04/01/2005</th>\n",
       "      <td>-0.008494</td>\n",
       "      <td>-0.010734</td>\n",
       "      <td>-0.006479</td>\n",
       "      <td>-0.018902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05/01/2005</th>\n",
       "      <td>0.012537</td>\n",
       "      <td>-0.005787</td>\n",
       "      <td>-0.004507</td>\n",
       "      <td>0.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/01/2005</th>\n",
       "      <td>0.009699</td>\n",
       "      <td>0.023645</td>\n",
       "      <td>0.013776</td>\n",
       "      <td>0.005716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07/01/2005</th>\n",
       "      <td>-0.005722</td>\n",
       "      <td>-0.003909</td>\n",
       "      <td>-0.004276</td>\n",
       "      <td>-0.008008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23/12/2010</th>\n",
       "      <td>-0.010571</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>-0.011792</td>\n",
       "      <td>-0.001897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27/12/2010</th>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.013305</td>\n",
       "      <td>0.014021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/12/2010</th>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>-0.003768</td>\n",
       "      <td>-0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29/12/2010</th>\n",
       "      <td>-0.002092</td>\n",
       "      <td>-0.013738</td>\n",
       "      <td>-0.009220</td>\n",
       "      <td>-0.005867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/12/2010</th>\n",
       "      <td>-0.002096</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>-0.003069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1510 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Citibank  Morgan Stanley  Goldman Sachs  J.P. Morgan\n",
       "Date                                                            \n",
       "03/01/2005  0.001868        0.006844       0.008747     0.003589\n",
       "04/01/2005 -0.008494       -0.010734      -0.006479    -0.018902\n",
       "05/01/2005  0.012537       -0.005787      -0.004507     0.002083\n",
       "06/01/2005  0.009699        0.023645       0.013776     0.005716\n",
       "07/01/2005 -0.005722       -0.003909      -0.004276    -0.008008\n",
       "...              ...             ...            ...          ...\n",
       "23/12/2010 -0.010571        0.000365      -0.011792    -0.001897\n",
       "27/12/2010  0.019231        0.003648       0.013305     0.014021\n",
       "28/12/2010  0.002096        0.005453      -0.003768    -0.001406\n",
       "29/12/2010 -0.002092       -0.013738      -0.009220    -0.005867\n",
       "30/12/2010 -0.002096        0.001833       0.000060    -0.003069\n",
       "\n",
       "[1510 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./crisis_portfolio.csv', index_col=0, parse_dates=True,date_format='%Y-%m-%d')\n",
    "df = df.pct_change().dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\87-Quantitative Risk Management in Python\\03-Estimating and identifying risk.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39;49mCitibank\u001b[39m.\u001b[39;49mresample(\u001b[39m'\u001b[39;49m\u001b[39mQ\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mdropna()\n",
      "File \u001b[1;32mc:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:9439\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[1;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[0;32m   9436\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   9437\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 9439\u001b[0m \u001b[39mreturn\u001b[39;00m get_resampler(\n\u001b[0;32m   9440\u001b[0m     cast(\u001b[39m\"\u001b[39;49m\u001b[39mSeries | DataFrame\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m),\n\u001b[0;32m   9441\u001b[0m     freq\u001b[39m=\u001b[39;49mrule,\n\u001b[0;32m   9442\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[0;32m   9443\u001b[0m     closed\u001b[39m=\u001b[39;49mclosed,\n\u001b[0;32m   9444\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   9445\u001b[0m     kind\u001b[39m=\u001b[39;49mkind,\n\u001b[0;32m   9446\u001b[0m     convention\u001b[39m=\u001b[39;49mconvention,\n\u001b[0;32m   9447\u001b[0m     key\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m   9448\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   9449\u001b[0m     origin\u001b[39m=\u001b[39;49morigin,\n\u001b[0;32m   9450\u001b[0m     offset\u001b[39m=\u001b[39;49moffset,\n\u001b[0;32m   9451\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   9452\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:1970\u001b[0m, in \u001b[0;36mget_resampler\u001b[1;34m(obj, kind, **kwds)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m \u001b[39mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[0;32m   1968\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m tg \u001b[39m=\u001b[39m TimeGrouper(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m-> 1970\u001b[0m \u001b[39mreturn\u001b[39;00m tg\u001b[39m.\u001b[39;49m_get_resampler(obj, kind\u001b[39m=\u001b[39;49mkind)\n",
      "File \u001b[1;32mc:\\Users\\jdamodhar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\resample.py:2160\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[1;34m(self, obj, kind)\u001b[0m\n\u001b[0;32m   2151\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[0;32m   2152\u001b[0m     \u001b[39mreturn\u001b[39;00m TimedeltaIndexResampler(\n\u001b[0;32m   2153\u001b[0m         obj,\n\u001b[0;32m   2154\u001b[0m         timegrouper\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2157\u001b[0m         gpr_index\u001b[39m=\u001b[39max,\n\u001b[0;32m   2158\u001b[0m     )\n\u001b[1;32m-> 2160\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   2161\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOnly valid with DatetimeIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2162\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2163\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got an instance of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(ax)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2164\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "df.Citibank.resample('Q').mean().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot of quarterly minimum portfolio returns\n",
    "plt.plot(port_q_min, label=\"Quarterly minimum return\")\n",
    "\n",
    "# Create a plot of quarterly mean volatility\n",
    "plt.plot(vol_q_mean, label=\"Quarterly mean volatility\")\n",
    "\n",
    "# Create legend and plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the statsmodels API to be able to run regressions\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant to the regression\n",
    "mort_del = sm.add_constant(mort_del)\n",
    "\n",
    "# Regress quarterly minimum portfolio returns against mortgage delinquencies\n",
    "result = sm.OLS(port_q_min, mort_del).fit()\n",
    "\n",
    "# Retrieve the sum-of-squared residuals\n",
    "ssr_total = result.ssr\n",
    "print(\"Sum-of-squared residuals, 2005-2010: \", ssr_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jdamodhar\\Desktop\\python_essential\\DataCamp-ds-deloitte-master\\00-A\\87-Quantitative Risk Management in Python\\03-Estimating and identifying risk.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Add intercept constants to each sub-period 'before' and 'after'\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m before_with_intercept \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39madd_constant(before[\u001b[39m'\u001b[39m\u001b[39mmort_del\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m after_with_intercept  \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39madd_constant(after[\u001b[39m'\u001b[39m\u001b[39mmort_del\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jdamodhar/Desktop/python_essential/DataCamp-ds-deloitte-master/00-A/87-Quantitative%20Risk%20Management%20in%20Python/03-Estimating%20and%20identifying%20risk.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Fit OLS regressions to each sub-period\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sm' is not defined"
     ]
    }
   ],
   "source": [
    "# Add intercept constants to each sub-period 'before' and 'after'\n",
    "before_with_intercept = sm.add_constant(before['mort_del'])\n",
    "after_with_intercept  = sm.add_constant(after['mort_del'])\n",
    "\n",
    "# Fit OLS regressions to each sub-period\n",
    "r_b = sm.OLS(before['returns'], before_with_intercept).fit()\n",
    "r_a = sm.OLS(after['returns'], after_with_intercept).fit()\n",
    "\n",
    "# Get sum-of-squared residuals for both regressions\n",
    "ssr_before = r_b.ssr\n",
    "ssr_after = r_a.ssr\n",
    "# Compute and display the Chow test statistic\n",
    "numerator = ((ssr_total - (ssr_before + ssr_after)) / 2)\n",
    "denominator = ((ssr_before + ssr_after) / (24 - 4))\n",
    "print(\"Chow test statistic: \", numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the time series of returns with and without Citibank\n",
    "ret_with_citi = prices_with_citi.pct_change().dot(weights_with_citi)\n",
    "ret_without_citi = prices_without_citi.pct_change().dot(weights_without_citi)\n",
    "\n",
    "# Find the average 30-day rolling window volatility as the standard deviation\n",
    "vol_with_citi = ret_with_citi.rolling(30).std().dropna().rename(\"With Citi\")\n",
    "vol_without_citi = ret_without_citi.rolling(30).std().dropna().rename(\"Without Citi\")\n",
    "\n",
    "# Combine two volatilities into one Pandas DataFrame\n",
    "vol = pd.concat([vol_with_citi, vol_without_citi], axis=1)\n",
    "\n",
    "# Plot volatilities over time\n",
    "vol.plot().set_ylabel(\"Losses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 95% VaR on 2009-2010 losses\n",
    "VaR_95 = np.quantile(estimate_data, 0.95)\n",
    "\n",
    "# Find backtest_data exceeding the 95% VaR\n",
    "extreme_values = backtest_data[backtest_data > VaR_95]\n",
    "\n",
    "# Compare the fraction of extreme values for 2007-2008 to the Var_95 estimate\n",
    "print(\"VaR_95: \", VaR_95, \"; Backtest: \", len(extreme_values) / len(backtest_data) )\n",
    "\n",
    "# Plot the extreme values and look for clustering\n",
    "plt.stem(extreme_values.index, extreme_values)\n",
    "plt.ylabel(\"Extreme values > VaR_95\"); plt.xlabel(\"Date\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
