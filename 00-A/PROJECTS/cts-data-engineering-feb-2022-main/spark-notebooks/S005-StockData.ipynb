{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "059d7912-2384-45e8-bd4c-58d1792b023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company Name: string (nullable = true)\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- Series: string (nullable = true)\n",
      " |-- ISIN Code: string (nullable = true)\n",
      "\n",
      "+------------------+------------------+----------+------+------------+\n",
      "|      Company Name|          Industry|    Symbol|Series|   ISIN Code|\n",
      "+------------------+------------------+----------+------+------------+\n",
      "|    Axis Bank Ltd.|FINANCIAL SERVICES|  AXISBANK|    EQ|INE238A01034|\n",
      "|Bajaj Finance Ltd.|FINANCIAL SERVICES|BAJFINANCE|    EQ|INE296A01024|\n",
      "+------------------+------------------+----------+------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sectorDf: org.apache.spark.sql.DataFrame = [Company Name: string, Industry: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sectorDf = spark.read\n",
    "                    .format(\"csv\")\n",
    "                    .option(\"header\", true)\n",
    "                    .option(\"inferSchema\", true)\n",
    "                    .option(\"delimitter\", \",\")\n",
    "                    .load(\"hdfs://localhost:9000/stocks/sectors\")\n",
    "\n",
    "sectorDf.printSchema()\n",
    "sectorDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14f36230-5c57-4813-9943-fd7334d8160b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StringType, StructType, DoubleType, IntegerType, LongType, StructField}\n",
       "SectorSchema: org.apache.spark.sql.types.StructType = StructType(StructField(CompanyName,StringType,true), StructField(Industry,StringType,true), StructField(Symbol,StringType,true), StructField(Series,StringType,true), StructField(ISIN,StringType,true))\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create a schema for dataframe using scala\n",
    "import org.apache.spark.sql.types.{StringType, StructType, DoubleType, \n",
    "                                   IntegerType, LongType, StructField }\n",
    "\n",
    "// SectorSchema\n",
    "val SectorSchema = StructType(\n",
    "         List(\n",
    "             StructField(\"CompanyName\", StringType, true), // true nullable\n",
    "             StructField(\"Industry\", StringType, true),\n",
    "             StructField(\"Symbol\", StringType, true),\n",
    "             StructField(\"Series\", StringType, true),\n",
    "             StructField(\"ISIN\", StringType, true)\n",
    "             )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fce3a9ba-f331-4c72-8fad-bf5017c0b4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CompanyName: string (nullable = true)\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Symbol: string (nullable = true)\n",
      " |-- Series: string (nullable = true)\n",
      " |-- ISIN: string (nullable = true)\n",
      "\n",
      "+------------------+------------------+----------+------+------------+\n",
      "|       CompanyName|          Industry|    Symbol|Series|        ISIN|\n",
      "+------------------+------------------+----------+------+------------+\n",
      "|    Axis Bank Ltd.|FINANCIAL SERVICES|  AXISBANK|    EQ|INE238A01034|\n",
      "|Bajaj Finance Ltd.|FINANCIAL SERVICES|BAJFINANCE|    EQ|INE296A01024|\n",
      "+------------------+------------------+----------+------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sectorDf: org.apache.spark.sql.DataFrame = [CompanyName: string, Industry: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Use the Schema\n",
    "val sectorDf = spark.read\n",
    "                    .format(\"csv\")\n",
    "                    .option(\"header\", true)\n",
    "                    .option(\"delimitter\", \",\")\n",
    "                    .schema(SectorSchema)\n",
    "                    .load(\"hdfs://localhost:9000/stocks/sectors\")\n",
    "\n",
    "sectorDf.printSchema()\n",
    "sectorDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "000ae2da-b18b-4871-88e8-178985f1199c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res18: Array[String] = Array(CompanyName, Industry, Symbol, Series, ISIN)\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectorDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8e560d2-12cb-4fea-b3ac-03fc567e3917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res19: Long = 200\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sectorDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be9fbc7f-6fa1-47e7-a2b8-63d9eb860370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Symbol: string (nullable = true)\n",
      "\n",
      "+------------------+----------+\n",
      "|          Industry|    Symbol|\n",
      "+------------------+----------+\n",
      "|FINANCIAL SERVICES|  AXISBANK|\n",
      "|FINANCIAL SERVICES|BAJFINANCE|\n",
      "|FINANCIAL SERVICES|BAJAJFINSV|\n",
      "|FINANCIAL SERVICES|  CHOLAFIN|\n",
      "|FINANCIAL SERVICES|   HDFCAMC|\n",
      "+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Industry: string, Symbol: string]\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = sectorDf.select(\"Industry\", \"Symbol\")\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "344a2f95-4b40-4bab-91e5-0cb06ba3724c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Industry|\n",
      "+--------------------+\n",
      "|          AUTOMOBILE|\n",
      "|        CONSTRUCTION|\n",
      "|      CONSUMER GOODS|\n",
      "|  FINANCIAL SERVICES|\n",
      "| HEALTHCARE SERVICES|\n",
      "|INDUSTRIAL MANUFA...|\n",
      "|                  IT|\n",
      "|MEDIA ENTERTAINME...|\n",
      "|              METALS|\n",
      "|           OIL & GAS|\n",
      "|              PHARMA|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// pick all industries, sort them in ascending order\n",
    "// output has ... format, means column values are truncated by show method\n",
    "sectorDf.select(\"Industry\").distinct().sort(\"Industry\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "269fb400-5f0f-4a43-b898-67a8eef3b931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|Industry                         |\n",
      "+---------------------------------+\n",
      "|AUTOMOBILE                       |\n",
      "|CONSTRUCTION                     |\n",
      "|CONSUMER GOODS                   |\n",
      "|FINANCIAL SERVICES               |\n",
      "|HEALTHCARE SERVICES              |\n",
      "|INDUSTRIAL MANUFACTURING         |\n",
      "|IT                               |\n",
      "|MEDIA ENTERTAINMENT & PUBLICATION|\n",
      "|METALS                           |\n",
      "|OIL & GAS                        |\n",
      "|PHARMA                           |\n",
      "+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// shows full column name\n",
    "sectorDf.select(\"Industry\").distinct().sort(\"Industry\").show(truncate = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65475782-766e-4935-a565-1ec69ef9aab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Industry|\n",
      "+--------------------+\n",
      "|              PHARMA|\n",
      "|           OIL & GAS|\n",
      "|              METALS|\n",
      "|MEDIA ENTERTAINME...|\n",
      "|                  IT|\n",
      "|INDUSTRIAL MANUFA...|\n",
      "| HEALTHCARE SERVICES|\n",
      "|  FINANCIAL SERVICES|\n",
      "|      CONSUMER GOODS|\n",
      "|        CONSTRUCTION|\n",
      "|          AUTOMOBILE|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{col, desc}\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{col, desc}\n",
    "// sectorDf(\"Industry\") represent col type\n",
    "// descending order\n",
    "sectorDf.select(sectorDf(\"Industry\")).distinct().sort(desc(\"Industry\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfa34f46-da10-48ed-b6e2-4e7f35046131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Industry|\n",
      "+--------------------+\n",
      "|              PHARMA|\n",
      "|           OIL & GAS|\n",
      "|              METALS|\n",
      "|MEDIA ENTERTAINME...|\n",
      "|                  IT|\n",
      "|INDUSTRIAL MANUFA...|\n",
      "| HEALTHCARE SERVICES|\n",
      "|  FINANCIAL SERVICES|\n",
      "|      CONSUMER GOODS|\n",
      "|        CONSTRUCTION|\n",
      "|          AUTOMOBILE|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{col, desc}\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{col, desc}\n",
    "// descending order\n",
    "sectorDf.select(col(\"Industry\")).distinct().sort(desc(\"Industry\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a18229b1-e76b-42f6-86e8-956f356eca47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Industry|\n",
      "+--------------------+\n",
      "|              PHARMA|\n",
      "|           OIL & GAS|\n",
      "|              METALS|\n",
      "|MEDIA ENTERTAINME...|\n",
      "|                  IT|\n",
      "|INDUSTRIAL MANUFA...|\n",
      "| HEALTHCARE SERVICES|\n",
      "|  FINANCIAL SERVICES|\n",
      "|      CONSUMER GOODS|\n",
      "|        CONSTRUCTION|\n",
      "|          AUTOMOBILE|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{col, desc}\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{col, desc}\n",
    "// descending order\n",
    "// $ is a special symbol in scala for spark to represent column name\n",
    "sectorDf.select($\"Industry\").distinct().sort(desc(\"Industry\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94b4a2d0-6364-4dfc-a4f8-d630200c93ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SYMBOL: string (nullable = true)\n",
      " |-- SERIES: string (nullable = true)\n",
      " |-- OPEN: double (nullable = true)\n",
      " |-- HIGH: double (nullable = true)\n",
      " |-- LOW: double (nullable = true)\n",
      " |-- CLOSE: double (nullable = true)\n",
      " |-- LAST: double (nullable = true)\n",
      " |-- PREVCLOSE: double (nullable = true)\n",
      " |-- TOTTRDQTY: integer (nullable = true)\n",
      " |-- TOTTRDVAL: double (nullable = true)\n",
      " |-- TIMESTAMP: timestamp (nullable = true)\n",
      " |-- TOTALTRADES: integer (nullable = true)\n",
      " |-- ISIN: string (nullable = true)\n",
      "\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+\n",
      "|    SYMBOL|SERIES|OPEN|HIGH| LOW|CLOSE| LAST|PREVCLOSE|TOTTRDQTY|    TOTTRDVAL|          TIMESTAMP|TOTALTRADES|        ISIN|\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+\n",
      "| 20MICRONS|    EQ|70.1|73.6|70.1|71.85|72.05|     71.2|   219912|1.583125505E7|2022-03-02 00:00:00|       2642|INE144J01027|\n",
      "|21STCENMGM|    EQ|29.6|29.6|29.6| 29.6| 29.6|     30.2|     1209|      35786.4|2022-03-02 00:00:00|         45|INE253B01015|\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stockDf: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 11 more fields]\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var stockDf = spark.read\n",
    "                    .format(\"csv\")\n",
    "                    .option(\"header\", true)\n",
    "                    .option(\"inferSchema\", true)\n",
    "                    .option(\"delimitter\", \",\")\n",
    "                    .option(\"timestampFormat\", \"dd-MMM-yyyy\")\n",
    "                    .load(\"hdfs://localhost:9000/stocks/daily\")\n",
    "                    .drop(\"_c13\")\n",
    "\n",
    "stockDf.printSchema()\n",
    "stockDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ecbc7aa-abde-4980-a0a6-9ba0ff9b2416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|    SYMBOL|TOTTRDQTY|\n",
      "+----------+---------+\n",
      "|ADANIPOWER| 37990829|\n",
      "|  ALOKINDS| 13696536|\n",
      "| AMBUJACEM|  6623505|\n",
      "|  ASHOKLEY| 13299580|\n",
      "|       AWL| 13334439|\n",
      "|  AXISBANK| 11691602|\n",
      "|BANDHANBNK|  7537231|\n",
      "|BANKBARODA| 47475131|\n",
      "|       BEL| 17202697|\n",
      "|BHARTIARTL| 10220908|\n",
      "|      BHEL| 33734292|\n",
      "|    BIOCON| 13122596|\n",
      "|      BPCL|  7734602|\n",
      "|     CANBK| 10972135|\n",
      "| COALINDIA| 72648396|\n",
      "|   CPSEETF|  6838326|\n",
      "|   DEVYANI|  5606901|\n",
      "|     DHANI| 37519005|\n",
      "|       DLF|  6854294|\n",
      "| FCONSUMER| 11838948|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// get the stocks where volume greater than 5 millions\n",
    "stockDf.filter ( $\"TOTTRDQTY\" > 5000000 )\n",
    "        .select(\"SYMBOL\", \"TOTTRDQTY\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42858598-f921-42d6-a653-4315969452bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------------+\n",
      "|SYMBOL    |TOTTRDQTY|TOTTRDVAL        |\n",
      "+----------+---------+-----------------+\n",
      "|ADANIPOWER|37990829 |4.70183548235E9  |\n",
      "|ALOKINDS  |13696536 |3.3159322015E8   |\n",
      "|AMBUJACEM |6623505  |2.02519921995E9  |\n",
      "|ASHOKLEY  |13299580 |1.56376581585E9  |\n",
      "|AWL       |13334439 |5.1355806697E9   |\n",
      "|AXISBANK  |11691602 |8.6334568352E9   |\n",
      "|BANDHANBNK|7537231  |2.2247190949E9   |\n",
      "|BANKBARODA|47475131 |4.91196164495E9  |\n",
      "|BEL       |17202697 |3.7135653097E9   |\n",
      "|BHARTIARTL|10220908 |6.87781912745E9  |\n",
      "|BHEL      |33734292 |1.6971618874E9   |\n",
      "|BIOCON    |13122596 |4.5562065457E9   |\n",
      "|BPCL      |7734602  |2.678648484E9    |\n",
      "|CANBK     |10972135 |2.36614299085E9  |\n",
      "|COALINDIA |72648396 |1.313502573215E10|\n",
      "|CPSEETF   |6838326  |2.2645909145E8   |\n",
      "|DEVYANI   |5606901  |8.953902411E8    |\n",
      "|DHANI     |37519005 |2.89349521655E9  |\n",
      "|DLF       |6854294  |2.36572027835E9  |\n",
      "|FEDERALBNK|15548463 |1.4921710391E9   |\n",
      "+----------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// get the stocks where volume greater than 5 millions and \n",
    "// traded value (amount) greater than 100 millions\n",
    "stockDf.filter ( ($\"TOTTRDQTY\" > 5000000) && ($\"TOTTRDVAL\" > 100000000 ))\n",
    "        .select(\"SYMBOL\", \"TOTTRDQTY\", \"TOTTRDVAL\").show(truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ffee275-5032-454c-b289-75d274add7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SYMBOL: string (nullable = true)\n",
      " |-- SERIES: string (nullable = true)\n",
      " |-- OPEN: double (nullable = true)\n",
      " |-- HIGH: double (nullable = true)\n",
      " |-- LOW: double (nullable = true)\n",
      " |-- CLOSE: double (nullable = true)\n",
      " |-- LAST: double (nullable = true)\n",
      " |-- PREVCLOSE: double (nullable = true)\n",
      " |-- TOTTRDQTY: integer (nullable = true)\n",
      " |-- TOTTRDVAL: double (nullable = true)\n",
      " |-- TIMESTAMP: timestamp (nullable = true)\n",
      " |-- TOTALTRADES: integer (nullable = true)\n",
      " |-- ISIN: string (nullable = true)\n",
      " |-- GAIN: double (nullable = true)\n",
      "\n",
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+-------------+-------------------+-----------+------------+--------------------+\n",
      "|    SYMBOL|SERIES|   OPEN|   HIGH|    LOW|  CLOSE|   LAST|PREVCLOSE|TOTTRDQTY|    TOTTRDVAL|          TIMESTAMP|TOTALTRADES|        ISIN|                GAIN|\n",
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+-------------+-------------------+-----------+------------+--------------------+\n",
      "| 20MICRONS|    EQ|   70.1|   73.6|   70.1|  71.85|  72.05|     71.2|   219912|1.583125505E7|2022-03-02 00:00:00|       2642|INE144J01027|                1.75|\n",
      "|21STCENMGM|    EQ|   29.6|   29.6|   29.6|   29.6|   29.6|     30.2|     1209|      35786.4|2022-03-02 00:00:00|         45|INE253B01015|                 0.0|\n",
      "| 3IINFOLTD|    EQ|  51.05|  51.35|   49.1|  49.45|   49.4|    51.45|  1092731| 5.46426994E7|2022-03-02 00:00:00|       7273|INE748C01038| -1.5999999999999943|\n",
      "|   3MINDIA|    EQ|21480.0|21480.0|20730.0|20923.1|20925.0|  21208.4|     1823|3.829445575E7|2022-03-02 00:00:00|       1120|INE470A01017|  -556.9000000000015|\n",
      "|    3PLAND|    BE|   15.9|  16.15|   14.8|   15.5|  15.65|    15.55|     8318|     128580.0|2022-03-02 00:00:00|         70|INE105C01023|-0.40000000000000036|\n",
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+-------------+-------------------+-----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stockDf: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 12 more fields]\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Scala we cause single quote without closing to represent column too 'OPEN\n",
    "stockDf = stockDf.withColumn(\"GAIN\", $\"CLOSE\" - 'OPEN)\n",
    "stockDf.printSchema()\n",
    "stockDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2513fbb7-4456-4e05-bc78-5794e989c044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+----+----+-----+---+\n",
      "|    SYMBOL|SERIES|OPEN|HIGH| LOW|CLOSE| LAST|PREVCLOSE|TOTTRDQTY|    TOTTRDVAL|          TIMESTAMP|TOTALTRADES|        ISIN|GAIN|Year|Month|Day|\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+----+----+-----+---+\n",
      "| 20MICRONS|    EQ|70.1|73.6|70.1|71.85|72.05|     71.2|   219912|1.583125505E7|2022-03-02 00:00:00|       2642|INE144J01027|1.75|2022|   03| 02|\n",
      "|21STCENMGM|    EQ|29.6|29.6|29.6| 29.6| 29.6|     30.2|     1209|      35786.4|2022-03-02 00:00:00|         45|INE253B01015| 0.0|2022|   03| 02|\n",
      "+----------+------+----+----+----+-----+-----+---------+---------+-------------+-------------------+-----------+------------+----+----+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.date_format\n",
       "stockDf: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 15 more fields]\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{date_format}\n",
    "stockDf = stockDf.withColumn(\"Year\", date_format($\"TIMESTAMP\", \"yyyy\"))\n",
    "                 .withColumn(\"Month\", date_format($\"TIMESTAMP\", \"MM\"))\n",
    "                 .withColumn(\"Day\", date_format($\"TIMESTAMP\", \"dd\"))   \n",
    "\n",
    "stockDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47fe1437-cd91-4d83-b50a-ab7c31fbc555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res34: Int = 2\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockDf.rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "000582ca-7f14-484d-bea6-6c98bab7db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockDf.write\n",
    "        .partitionBy(\"Year\", \"Month\", \"Day\")\n",
    "        .format(\"parquet\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"hdfs://localhost:9000/stock-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f28909c6-e347-4e75-a702-06910438b3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allData: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 15 more fields]\n",
       "res36: Long = 4370\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// read data from all teh data from stock-data\n",
    "// all years, all month, all days, all files\n",
    "val allData = spark.read.format(\"parquet\")\n",
    "                    .load(\"hdfs://localhost:9000/stock-data\")\n",
    "allData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04076437-e76f-4994-836c-532712fc29ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allData2022: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 14 more fields]\n",
       "res37: Long = 4370\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// read data from specific year 2022\n",
    "val allData2022 = spark.read.format(\"parquet\")\n",
    "                    .load(\"hdfs://localhost:9000/stock-data/Year=2022\")\n",
    "allData2022.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ad4ed75-e9e4-4eb1-9d37-ba2e4d3ed278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allData2022Month03: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 13 more fields]\n",
       "res38: Long = 4370\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// read data from specific year 2022 Month 03\n",
    "val allData2022Month03 = spark.read.format(\"parquet\")\n",
    "                    .load(\"hdfs://localhost:9000/stock-data/Year=2022/Month=03\")\n",
    "allData2022Month03.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea734879-5576-4c32-91bc-be4639386246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allData2022Month03Day02: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 12 more fields]\n",
       "res39: Long = 2198\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// read data from specific year 2022 Month 03 day 02\n",
    "val allData2022Month03Day02 = spark.read.format(\"parquet\")\n",
    "                    .load(\"hdfs://localhost:9000/stock-data/Year=2022/Month=03/Day=02\")\n",
    "allData2022Month03Day02.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed196e-eb1a-4474-b7d3-f7d346691477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
