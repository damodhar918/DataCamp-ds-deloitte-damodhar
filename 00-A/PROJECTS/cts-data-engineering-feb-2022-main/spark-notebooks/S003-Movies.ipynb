{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb1c30bb-d4e8-4614-b39d-7c8549612d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.80.128:4041\n",
       "SparkContext available as 'sc' (version = 2.4.7, master = local[*], app id = local-1646252013108)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "moviesRdd: org.apache.spark.rdd.RDD[String] = hdfs://localhost:9000/movies/movies.csv MapPartitionsRDD[1] at textFile at <console>:25\n",
       "ratingRdd: org.apache.spark.rdd.RDD[String] = hdfs://localhost:9000/ratings/ratings.csv MapPartitionsRDD[3] at textFile at <console>:26\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val moviesRdd =  sc.textFile(\"hdfs://localhost:9000/movies/movies.csv\")\n",
    "val ratingRdd = sc.textFile(\"hdfs://localhost:9000/ratings/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586b7d26-32c4-4b63-af7c-e1815211ba88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: Long = 9743\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesRdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3245ce29-c989-41fc-8724-44fa9d0d8659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: Long = 100837\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingRdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0e01e71-ba78-47af-a21e-98ba3655cecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: String = movieId,title,genres\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesRdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e744f523-9254-411c-9749-4a969eb446b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: String = userId,movieId,rating,timestamp\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingRdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "579da1dc-0f1e-47f4-bfed-c549faeb5137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "header: String = movieId,title,genres\n",
       "moviesContentRdd: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[4] at filter at <console>:27\n",
       "res8: Array[String] = Array(1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy, 2,Jumanji (1995),Adventure|Children|Fantasy)\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val header = moviesRdd.first()\n",
    "val moviesContentRdd = moviesRdd.filter (line => line != header)\n",
    "moviesContentRdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47d4b41-97b7-49f8-88d5-2ca2020ec595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rheader: String = userId,movieId,rating,timestamp\n",
       "ratingsContentRdd: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5] at filter at <console>:27\n",
       "res9: Array[String] = Array(1,1,4.0,964982703, 1,3,4.0,964981247)\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rheader = ratingRdd.first()\n",
    "val ratingsContentRdd = ratingRdd.filter (line => line != rheader)\n",
    "ratingsContentRdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c8940a5-f116-4ae3-8713-ee405e21b20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "moviesParsedRdd: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[16] at map at <console>:32\n",
       "res21: Array[Array[String]] = Array(Array(1, Toy Story (1995), Adventure|Animation|Children|Comedy|Fantasy), Array(2, Jumanji (1995), Adventure|Children|Fantasy), Array(3, Grumpier Old Men (1995), Comedy|Romance), Array(4, Waiting to Exhale (1995), Comedy|Drama|Romance))\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// parse moviescsv without header input tuple\n",
    "val moviesParsedRdd = moviesContentRdd\n",
    "                        .map (line => line.trim())\n",
    "                        .filter ( line => !line.isEmpty())\n",
    "                        .map ( line => line.split(\",\"))\n",
    "moviesParsedRdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25f91a4b-5ec6-4865-a335-35f415c8695e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "moviesTupleRdd: org.apache.spark.rdd.RDD[(Int, (String, String))] = MapPartitionsRDD[25] at map at <console>:30\n",
       "res28: Array[(Int, (String, String))] = Array((1,(Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy)), (2,(Jumanji (1995),Adventure|Children|Fantasy)), (3,(Grumpier Old Men (1995),Comedy|Romance)), (4,(Waiting to Exhale (1995),Comedy|Drama|Romance)))\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// convert moviesParsedRdd into tuple of 3 elements \n",
    "// (INT, String, String), using _1, _2, _3\n",
    "val moviesTupleRdd = moviesParsedRdd.map (arr => (arr(0).toInt, (arr(1), arr(2) ) ) )\n",
    "moviesTupleRdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb5e8b25-da32-4058-97b0-a3d69c44660b",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.SparkDriverExecutionException",
     "evalue": " Execution error",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.SparkDriverExecutionException: Execution error",
      "  at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1400)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2143)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)",
      "  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)",
      "  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)",
      "  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1409)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
      "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)",
      "  at org.apache.spark.rdd.RDD.take(RDD.scala:1382)",
      "  ... 30 elided",
      "Caused by: java.lang.ArrayStoreException: [LMovie;",
      "  at scala.runtime.ScalaRunTime$.array_update(ScalaRunTime.scala:90)",
      "  at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:2082)",
      "  at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:2082)",
      "  at org.apache.spark.scheduler.JobWaiter.taskSucceeded(JobWaiter.scala:59)",
      "  at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1396)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2143)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)",
      "  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)",
      ""
     ]
    }
   ],
   "source": [
    "// FIXME: \n",
    "// using case class , domain object\n",
    "// case class Movie(id: Int, title: String, genres: String)\n",
    "// val moviesDataRdd = moviesTupleRdd.map ( t => Movie(t._1, t._2, t._3))\n",
    "// moviesDataRdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f44a1eba-c84e-4665-8a70-b2993dc2c439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratingParsedRdd: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[22] at map at <console>:29\n",
       "res25: Array[Array[String]] = Array(Array(1, 1, 4.0, 964982703), Array(1, 3, 4.0, 964981247), Array(1, 6, 4.0, 964982224), Array(1, 47, 5.0, 964983815))\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ratingParsedRdd = ratingsContentRdd\n",
    "                        .map (line => line.trim())\n",
    "                        .filter ( line => !line.isEmpty())\n",
    "                        .map ( line => line.split(\",\"))\n",
    "\n",
    "ratingParsedRdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63dc995e-5616-44e2-8a24-c082feb53879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratingsTupleRdd: org.apache.spark.rdd.RDD[(Int, (Int, Double, Long))] = MapPartitionsRDD[26] at map at <console>:30\n",
       "res29: Array[(Int, (Int, Double, Long))] = Array((1,(1,4.0,964982703)), (3,(1,4.0,964981247)), (6,(1,4.0,964982224)), (47,(1,5.0,964983815)))\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// get ratings in tuple format\n",
    "// bring the movieId to first member\n",
    "val ratingsTupleRdd = ratingParsedRdd.map (rating => (rating(1).toInt, //movieId\n",
    "                                                      (rating(0).toInt, //  userId\n",
    "                                                      rating(2).toDouble, //rating\n",
    "                                                      rating(3).toLong ) // timestamp\n",
    "                                                     ))\n",
    "                                           \n",
    "ratingsTupleRdd.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25c32873-3513-4ec1-b8cd-b8ab2150a68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outputRdd: org.apache.spark.rdd.RDD[(Int, ((String, String), (Int, Double, Long)))] = MapPartitionsRDD[32] at join at <console>:28\n",
       "res30: Array[(Int, ((String, String), (Int, Double, Long)))] = Array((1084,((Bonnie and Clyde (1967),Crime|Drama),(4,5.0,945079259))), (1084,((Bonnie and Clyde (1967),Crime|Drama),(6,3.0,845555454))), (1084,((Bonnie and Clyde (1967),Crime|Drama),(32,4.0,856737338))))\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val outputRdd = moviesTupleRdd.join(ratingsTupleRdd)\n",
    "outputRdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2868b4c-1324-44ea-998e-aec2d841ee25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
