{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b443d76-f6a2-44bd-a456-b2a8acf0cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0d42b2e-06eb-42e0-81c1-5efa9ad29094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/02 22:35:37 WARN Utils: Your hostname, ubuntu-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.80.128 instead (on interface ens33)\n",
      "22/03/02 22:35:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/03/02 22:35:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "# local is master, embedded inside same jvm\n",
    "# local -1 parallism - good for debugging, 1 task shall at a time\n",
    "# local[2] - 2 parallisms , 2 task4 can run at same time\n",
    "# local[4] - 4 parallisms , 4 task4 can run at same time\n",
    "# local[*] -  number of parallism is based on number of cores in the system\n",
    "sc = SparkContext(\"local[8]\", \"LocalMaster\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d644eeb-14b1-440f-a412-bdaa87c4e001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  defaultParallelism  8\n",
      "  defaultMinPartitions  2\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8, 9, 5, 1, 4, 7, 2, 6, 3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are from configuration, based on number of parallel tasks\n",
    "print(\"  defaultParallelism \", sc.defaultParallelism)\n",
    "print(\"  defaultMinPartitions \", sc.defaultMinPartitions)\n",
    "\n",
    "rdd = sc.parallelize(range(1, 10))\n",
    "rdd = rdd.repartition(500)\n",
    "print(rdd.getNumPartitions()) # sc.defaultParallelism\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad76b6a8-2d0f-4830-a7f9-f9c5232420b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fada394-e4fd-4185-ac4d-c101dcbc73a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prince dont welcome'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to remove special chars\n",
    "# we will all ascii\n",
    "def to_ascii(text):\n",
    "    import re\n",
    "    output = re.sub(r\"[^a-zA-Z0-9 ]\",\"\",text)\n",
    "    #print(output)\n",
    "    return output\n",
    "\n",
    "text = \"prince, don't ;welcome\"\n",
    "to_ascii(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05969d9f-0817-4439-9dbe-6198f2f6c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCountRdd = sc.textFile(\"hdfs://localhost:9000/book-war-and-peace.txt\")\\\n",
    "                 .map (lambda line: to_ascii(line))\\\n",
    "                  .map (lambda line: line.strip().lower())\\\n",
    "                 .map (lambda line: line.split(\" \"))\\\n",
    "                 .flatMap(lambda elements: elements)\\\n",
    "                 .filter (lambda word: word != \"\")\\\n",
    "                 .map (lambda word: (word, 1))\\\n",
    "                 .reduceByKey(lambda acc, value: acc + value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f0e44f6-4d40-4b9e-99a8-f7e0d5c6e798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('chapter', 367),\n",
       " ('i', 4089),\n",
       " ('well', 741),\n",
       " ('prince', 1886),\n",
       " ('so', 1852),\n",
       " ('genoa', 3),\n",
       " ('and', 22082),\n",
       " ('lucca', 2),\n",
       " ('are', 1259),\n",
       " ('now', 1305)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wordCountRdd.cache() # , call persit internally with MEMORY_ONLY\n",
    "\n",
    "wordCountRdd.persist(StorageLevel.MEMORY_AND_DISK) # we have many options\n",
    "#wordCountRdd.persist(StorageLevel.DISK_ONLY) # we have many options\n",
    "\n",
    "wordCountRdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91608f02-08d4-4206-a56c-f0aacec53dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('infamies', 1),\n",
       " ('yousit', 1),\n",
       " ('elite', 1),\n",
       " ('scarletliveried', 1),\n",
       " ('10annette', 1),\n",
       " ('grandfathers', 1),\n",
       " ('canceled', 1),\n",
       " ('woundup', 1),\n",
       " ('tease', 1),\n",
       " ('novosiltsevs', 1)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort data by value, in ascending order\n",
    "# least used words\n",
    "\n",
    "sortedRddAscending = wordCountRdd.sortBy(lambda kv: kv[1])\n",
    "\n",
    "sortedRddAscending.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef437ad8-7e34-4209-a56a-1adb1ff85b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 34395),\n",
       " ('and', 22082),\n",
       " ('to', 16636),\n",
       " ('of', 14872),\n",
       " ('a', 10464),\n",
       " ('he', 9807),\n",
       " ('in', 8744),\n",
       " ('his', 7967),\n",
       " ('that', 7798),\n",
       " ('was', 7328)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sortBy values but decending order\n",
    "# most used words\n",
    "print(wordCountRdd.getNumPartitions())\n",
    "sortedRddDecending = wordCountRdd.sortBy(lambda kv: kv[1], ascending=False)\n",
    "sortedRddDecending.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f1663f0-1e8a-401b-80f3-ad76325f9a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCountRdd.saveAsTextFile(\"hdfs://localhost:9000/war-and-peace-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0453c0f3-81e5-4eb6-b88c-c8d259396dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedRddDecending.saveAsTextFile(\"hdfs://localhost:9000/war-and-peace-sorted-desc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2ad59f5-b4c7-47ba-bf97-3936ebf9fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedRddAscending.saveAsTextFile(\"hdfs://localhost:9000/war-and-peace-sorted-asc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e8ad9f-4450-4301-94fc-aa1fb03a64db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
