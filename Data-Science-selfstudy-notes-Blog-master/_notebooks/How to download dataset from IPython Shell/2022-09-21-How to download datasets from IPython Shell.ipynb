{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to download datasets from IPython Shell in Datacamp\n",
    "> This blog post will show you how to download datasets from DataCamp Ipython Shell/Console in a web browser.\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Datacamp\n",
    "- categories: [DataCamp, Dataset, Download, IPython Shell]\n",
    "- image: images/datacamp.png\n",
    "- hide: false\n",
    "- search_exclude: true\n",
    "- metadata_key1: metadata_value1\n",
    "- metadata_key2: metadata_value2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> **TL;DR:** Use the python [script](#Full-Code) to extract the link to download the targeting datasets from IPython Shell.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation**: While studying DataCamp courses, there were so many times that I could not reproduce the course results in my local environment with the provided datasets, which was quite frustrating. I had tried to reach out to the support team, but the results were not satisfactory. After spending hours searching on Stackoverflow [here](https://stackoverflow.com/questions/31893930/download-csv-from-an-ipython-notebook) and [there](https://stackoverflow.com/questions/26497912/trigger-file-download-within-ipython-notebook), then trying and failing numerous times with several scripts, I could finally manage to download the dataset that the course was using.\n",
    "\n",
    "I decided to share my workaround here. Hopefully, it could help everyone who is facing the same problems. <br>\n",
    "\n",
    "I have summarized how I did it in the following steps:\n",
    "- [**1.**](#Quick-EDA) Check the general info of the dataset\n",
    "- [**2.**](#Save-the-dataset-to-the-cloud-storage) Put the download script to the script.py\n",
    "- [**3.**](#Encode-the-file-data-and-an-generate-HTML-link) Extract the \"href \"link, and download it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick EDA\n",
    "\n",
    "Run the following command to take do a quick check on the data\n",
    "\n",
    "```python\n",
    "print(df.head())\n",
    "\n",
    "                   y\n",
    "2013-01-01  1.624345\n",
    "2013-01-02 -0.936625\n",
    "2013-01-03  0.081483\n",
    "2013-01-04 -0.663558\n",
    "2013-01-05  0.738023\n",
    "\n",
    "```\n",
    "\n",
    "then a quick look with ```df.info()```\n",
    "\n",
    "```python\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "DatetimeIndex: 1000 entries, 2013-01-01 to 2015-09-27\n",
    "Freq: D\n",
    "Data columns (total 1 columns):\n",
    " #   Column  Non-Null Count  Dtype  \n",
    "---  ------  --------------  -----  \n",
    " 0   y       1000 non-null   float64\n",
    "dtypes: float64(1)\n",
    "memory usage: 55.6 KB\n",
    "None\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the dataset has 1000 rows, with Freq set as Date, Dtype = float64, etc.\n",
    "\n",
    "Here are the first 5 rows of data:\n",
    "\n",
    "```console\n",
    "2013-01-01  1.624345\n",
    "2013-01-02 -0.936625\n",
    "2013-01-03  0.081483\n",
    "2013-01-04 -0.663558\n",
    "2013-01-05  0.738023\n",
    "```\n",
    "We will remember this, so we can check later once we download the dataset to our local environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the dataset to the cloud storage\n",
    "\n",
    "Next, we will save the dataset from the DataFrame to the cloud storage. Try the following code in the script.py.\n",
    "\n",
    "![](./images/tempsnip.png)\n",
    "\n",
    "CODE:\n",
    "```python \n",
    "# Get the filename fullpath\n",
    "from pathlib import Path\n",
    "\n",
    "filename = \"data.csv\"\n",
    "filename = Path.cwd() / filename\n",
    "df.to_csv(filename)\n",
    "```\n",
    "<br>\n",
    "\n",
    "Check the result by typing the following commands to the IPython Shell: <br>\n",
    "\n",
    "```console\n",
    "!pwd\n",
    "!ls\n",
    "```\n",
    "\n",
    "![](./images/tempsnip2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the file data and an generate HTML link\n",
    "\n",
    "Next, we run the following code, to generate HTML data.  \n",
    "\n",
    "```python\n",
    "import base64\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "\n",
    "in_file  = open(filename, \"rb\")\n",
    "csv = in_file.read()\n",
    "# print(csv) # Uncomment this if you want to check the csv content\n",
    "in_file.close()\n",
    "\n",
    "b64 = base64.b64encode(csv)\n",
    "payload = b64.decode()\n",
    "html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "html = html.format(payload=payload,title=title,filename=filename)\n",
    "# Print the link\n",
    "print(\"data:text/csv;base64,{}\".format(payload))\n",
    "```\n",
    "<br>\n",
    "\n",
    "**Result:** <br>\n",
    "\n",
    "![](./images/tempsnip3.png)\n",
    "\n",
    "Paste the extracted link in the Shell output to a new tab in the browser. \n",
    "<br>\n",
    "\n",
    "\n",
    "![](./images/tempsnip4.PNG)\n",
    "<br>\n",
    "\n",
    "**Voila**! That is the dataset that we want. <br>\n",
    "\n",
    "![](./images/tempsnip5.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the downloaded dataset in your local Jupyter notebook\n",
    "\n",
    "Use this code: <br>\n",
    "\n",
    "```python\n",
    "\n",
    "df = pd.read_csv('./datasets/download.csv', parse_dates=True, index_col=[0])\n",
    "df = df.asfreq('d')  # Set the frequent as DATE \n",
    "df.info()\n",
    "\n",
    "```\n",
    "\n",
    "then <br>\n",
    "\n",
    "```python\n",
    "df.head()\n",
    "```\n",
    "\n",
    "Results: <br>\n",
    "\n",
    "![](./images/tempsnip6.PNG)\n",
    "\n",
    "<br>\n",
    "\n",
    "As you can see, the downloaded dataset looks exactly like what we saw in the quick [EDA](#quick-eda) section. You can now freely run your experiment locally with no worries about preprocessing the raw datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Code\n",
    "Here is the full code of the post. Use this script in the script.py, you should be able to download the targeted datasets.\n",
    "\n",
    "\n",
    "```python \n",
    "\n",
    "import base64\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def create_download_link( df, title = \"Download CSV file\", filename = \"data.csv\"):\n",
    "\n",
    "    filename = Path.cwd() / filename\n",
    "    df.to_csv(filename)\n",
    "\n",
    "    in_file  = open(filename, \"rb\")\n",
    "    csv = in_file.read()\n",
    "    # print(csv) # Uncomment this if you want to check the csv content\n",
    "    in_file.close()\n",
    "\n",
    "    b64 = base64.b64encode(csv)\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    # print the link\n",
    "    print(\"data:text/csv;base64,{}\".format(payload))\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(df)\n",
    "print(df.info())\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **BONUS**: &nbsp; Here is another version of the code. It was modified to help downloading numpy arrays. \n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def create_download_link( numpy_arr, title = \"Download CSV file\", filename = \"data.csv\"):\n",
    "    # CONVERT numpy array to pandas frame. \n",
    "    df = pd.DataFrame(numpy_arr) \n",
    "\n",
    "    filename = Path.cwd() / filename\n",
    "    df.to_csv(filename)\n",
    "\n",
    "    in_file  = open(filename, \"rb\")\n",
    "    csv = in_file.read()\n",
    "    # print(csv) # Uncomment this if you want to check the csv content\n",
    "    in_file.close()\n",
    "\n",
    "    b64 = base64.b64encode(csv)\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    # print the link\n",
    "    print(\"data:text/csv;base64,{}\".format(payload))\n",
    "    return HTML(html)\n",
    "\n",
    "create_download_link(new_inputs)\n",
    "```\n",
    "\n",
    "\n",
    "Then we can reload the downloaded numpy array as follows. \n",
    "\n",
    "```python\n",
    "\n",
    "new_inputs_df = pd.read_csv('./datasets/data.csv', index_col=[0])\n",
    "new_inputs = new_inputs_df.to_numpy()\n",
    "new_inputs.reshape((100,))  # CONVERT it back to its original shape. \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **OTHER NOTE:** &nbsp; To see the pre-defined function from the scripts.py use the following script:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "import inspect\n",
    "source = inspect.getsource(pre_defined_fucntion_name)\n",
    "print(source)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **UPDATE (2022 Oct 13)** <br>\n",
    "\n",
    "In the above methods, it seems like that **base64.b64encode** create a TOO LONG string data when encoding the large table (Ex: Tables have more than 6500 rows). The download link is too long, and therefore nolonger possible to be loaded by the browser. The data will be lost if we use the above method. It will be trickier to download the data in these cases without encoding data with base64. \n",
    "\n",
    "One can think of using some string compression method to make the string shorter, but that is not feasible when huge tables present. \n",
    "\n",
    "As an alternative, we can download the csv data as string in bytes format by:\n",
    "-  Manually copying data from the terminal\n",
    "-  Save it as .txt format\n",
    "-  Finally, reload it back to the original form. \n",
    "\n",
    "In details:\n",
    "\n",
    "- **STEP 1:** Download the data as \"data.txt\" file. <br>\n",
    "\n",
    "```python\n",
    "\n",
    "print(numpy_arr)\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def create_download_link(numpy_arr, filename = \"data.csv\"):\n",
    "    # CONVERT numpy array to pandas frame. \n",
    "    df = pd.DataFrame(numpy_arr) \n",
    "\n",
    "    filename = Path.cwd() / filename\n",
    "    df.to_csv(filename)\n",
    "\n",
    "    with open(filename, \"rb\") as in_file:\n",
    "        csv_data = in_file.read()\n",
    "\n",
    "        # print(\"data:text/csv;charset=utf-8,{}\".format(csv_data)) --> not working since '\\\\n' is not the actual new line char anymore. \n",
    "        # print(\"data:text/plain;charset=utf-8,{}\".format(csv_data)) # save the byte data as plain text\n",
    "        print(csv_data, '\\n\\n\\n') # if the browser can not cover all character, we ll paste the data to .txt file directly \n",
    "\n",
    "create_download_link(abnormal)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "- **STEP 2:** Load the \"data.txt\" file, and convert it back to normal csv format file. <br>\n",
    "\n",
    "```python\n",
    "\n",
    "import re, csv, os\n",
    "file_path = './datasets/all_prices.txt'\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    plain_str = f.read()\n",
    "    print(plain_str[:10], plain_str[-10:])\n",
    "\n",
    "    # remove byte traces\n",
    "    csv_data = re.match(r\".*?b\\'(.*)\\'.*?\", plain_str).group(1) \n",
    "    print(\"START:\\n\",csv_data[:250],\"\\nEND:\", csv_data[-250:])\n",
    "\n",
    "    # remove \\\\n with actual new line chars\n",
    "    csv_data = csv_data.replace('\\\\n', '\\n') \n",
    "    print(\"START:\\n\",csv_data[:250],\"\\nEND:\", csv_data[-250:])\n",
    "\n",
    "    # update csv format to the filename\n",
    "    with open(os.path.splitext(file_path)[0] + '.csv', 'w') as out:\n",
    "        out.write(csv_data)\n",
    "\n",
    "```\n",
    "\n",
    "- **STEP 3:**  Load the csv data as usual, we can also convert it to numpy array if we want. <br>\n",
    "\n",
    "```python\n",
    "\n",
    "# Read in the data\n",
    "df = pd.read_csv('./datasets/data.csv', index_col=[0])\n",
    "print(df.info())\n",
    "display(df.tail())\n",
    "\n",
    "new_np_arr = df.to_numpy()\n",
    "print(new_np_arr.shape)\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. Thank you for reading. If you find the blog post useful, please give the [GitHub blog repo](https://github.com/anhhaibkhn/Data-Science-selfstudy-notes-Blog) a star to show your support and share it with others. Also, please let me know in the comments section of the post if you have any questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('my_conda_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f080ef3f7e154a5496448b61eb994fbc79c03fae547c033702ffc1b7b2a346b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
