{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Winning a Kaggle Competition in Python - Part 3\n",
    "\n",
    "> Feature Engineering - You will now get exposure to different types of features. You will modify existing features and create new ones. Also, you will treat the missing data accordingly.\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Hai Nguyen\n",
    "- categories: [Kaggle, Datacamp,  Feature Engineering, Encoding, Cross-Validation, K-fold, Imputing, Missing-Data]\n",
    "- image: images/winning_kaggle_p3.png\n",
    "- hide: false\n",
    "- search_exclude: true\n",
    "- metadata_key1: metadata_value1\n",
    "- metadata_key2: metadata_value2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Download Datasets and Presentation slides for this post HERE**](https://github.com/anhhaibkhn/Data-Science-selfstudy-notes-Blog/tree/master/_notebooks/Winning%20a%20Kaggle%20Competition%20in%20Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "![Solution Workflow](./images/solution_workflow2.png)\n",
    "\n",
    "\n",
    "Like a Marathon, we iterate the following processs:\n",
    "\n",
    "![Modeling](./images/modeling.png)\n",
    "\n",
    "\n",
    "\n",
    "Feature Engineering with Domain Knowledge:\n",
    "\n",
    "![Domain](./images/domain.png)\n",
    "\n",
    "\n",
    "Feature Types:\n",
    "- Numerical \n",
    "- Categorical\n",
    "- Datetime\n",
    "- Coordinates\n",
    "- Text\n",
    "- Images\n",
    "etc.\n",
    "\n",
    "\n",
    "Creating Features:\n",
    "\n",
    "![Creating Features](./images/creating_features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetical features\n",
    "![](./images/Arithm_features.png)\n",
    "\n",
    "\n",
    "Arithmetical features (Exercise):\n",
    "\n",
    "To practice creating new features, you will be working with a subsample from the Kaggle competition called \"House Prices: Advanced Regression Techniques\". The goal of this competition is to predict the price of the house based on its properties. It's a regression problem with Root Mean Squared Error as an evaluation metric.\n",
    "\n",
    "Your goal is to create new features and determine whether they improve your validation score. To get the validation score from 5-fold cross-validation, you're given the get_kfold_rmse() function. Use it with the train DataFrame, available in your workspace, as an argument.\n",
    "\n",
    "Instructions:\n",
    "- Create a new feature representing the total area (basement, 1st and 2nd floors) of the house. The columns \"TotalBsmtSF\", \"FirstFlrSF\" and \"SecondFlrSF\" give the areas of the basement, 1st and 2nd floors, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./datasets/house_prices_train.csv')\n",
    "test = pd.read_csv('./datasets/house_prices_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE before feature engineering: 36029.39\n",
      "RMSE with total area: 35073.2\n",
      "RMSE with garden area: 34413.55\n",
      "RMSE with number of bathrooms: 34506.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "def get_kfold_rmse(train):\n",
    "    mse_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        train = train.fillna(0)\n",
    "        feats = [x for x in train.columns if x not in ['Id', 'SalePrice', 'RoofStyle', 'CentralAir']]\n",
    "        \n",
    "        fold_train, fold_test = train.loc[train_index], train.loc[test_index]\n",
    "\n",
    "        # Fit the data and make predictions\n",
    "        # Create a Random Forest object\n",
    "        rf = RandomForestRegressor(n_estimators=10, min_samples_split=10, random_state=123)\n",
    "\n",
    "        # Train a model\n",
    "        rf.fit(X=fold_train[feats], y=fold_train['SalePrice'])\n",
    "\n",
    "        # Get predictions for the test set\n",
    "        pred = rf.predict(fold_test[feats])\n",
    "    \n",
    "        fold_score = mean_squared_error(fold_test['SalePrice'], pred)\n",
    "        mse_scores.append(np.sqrt(fold_score))\n",
    "        \n",
    "    return round(np.mean(mse_scores) + np.std(mse_scores), 2)\n",
    "\n",
    "\n",
    "\n",
    "# Look at the initial RMSE\n",
    "print('RMSE before feature engineering:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the total area of the house\n",
    "train['TotalArea'] = train['TotalBsmtSF'] + train['1stFlrSF'] + train['2ndFlrSF']\n",
    "print('RMSE with total area:', get_kfold_rmse(train))\n",
    "\n",
    "# Find the area of the garden\n",
    "train['GardenArea'] = train['LotArea'] - train['1stFlrSF']\n",
    "print('RMSE with garden area:', get_kfold_rmse(train))\n",
    "\n",
    "# Find total number of bathrooms\n",
    "train['TotalBath'] = train[\"FullBath\"] + train[\"HalfBath\"]\n",
    "print('RMSE with number of bathrooms:', get_kfold_rmse(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Nice! You've created three new features. Here you see that house area improved the RMSE by almost 1,000 USD. Adding garden area improved the RMSE by another 600. However, with the total number of bathrooms, the RMSE has increased. It means that you keep the new area features, but DO NOT ADD \"TotalBath\" as a new feature. Let's now work with the datetime features! </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date features\n",
    "![](./images/date_features.png)\n",
    "\n",
    "\n",
    "then we can use pandas dt method, to get the attributes which we want.\n",
    "\n",
    "![](./images/date_features2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date features (Exercise):\n",
    "\n",
    "You've built some basic features using numerical variables. Now, it's time to create features based on date and time. You will practice on a subsample from the Taxi Fare Prediction Kaggle competition data. The data represents information about the taxi rides and the goal is to predict the price for each ride.\n",
    "\n",
    "Your objective is to generate date features from the pickup datetime. Recall that it's better to create new features for train and test data simultaneously. After the features are created, split the data back into the train and test DataFrames. Here it's done using pandas' isin() method.\n",
    "\n",
    "The train and test DataFrames are already available in your workspace.\n",
    "\n",
    "Instructions:\n",
    "- Concatenate the train and test DataFrames into a single DataFrame taxi.\n",
    "- Convert the \"pickup_datetime\" column to a datetime object.\n",
    "- Create the day of week (using .dayofweek attribute) and hour (using .hour attribute) features from the \"pickup_datetime\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./datasets/taxi_train_chapter_4.csv')\n",
    "test = pd.read_csv('./datasets/taxi_test_chapter_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test together\n",
    "taxi = pd.concat([train, test])\n",
    "\n",
    "# Convert pickup date to datetime object\n",
    "taxi['pickup_datetime'] = pd.to_datetime(taxi['pickup_datetime'])\n",
    "\n",
    "# Create a day of week feature\n",
    "taxi['dayofweek'] = taxi['pickup_datetime'].dt.dayofweek\n",
    "\n",
    "# Create an hour feature\n",
    "taxi['hour'] = taxi['pickup_datetime'].dt.hour\n",
    "\n",
    "# Split back into train and test\n",
    "new_train = taxi[taxi['id'].isin(train['id'])]\n",
    "new_test = taxi[taxi['id'].isin(test['id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now you know how to perform feature engineering for train and test DataFrames simultaneously. Having considered numerical and datetime features, move forward to master feature engineering for categorical ones!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Categorical features\n",
    "\n",
    "![](./images/categorical_features.png)\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "![](./images/categorical_features2.png)\n",
    "\n",
    "\n",
    "Label encoding is working, but it may affect to the results since it creates ranking data:\n",
    "\n",
    "![](./images/categorical_features3.png)\n",
    "\n",
    "\n",
    "To overcome the label encoding problem, use One-Hot encoding:\n",
    "![](./images/onehot.png)\n",
    "\n",
    "Binary Features:\n",
    "![](./images/binary_feat.png)\n",
    "\n",
    "Other encoding methods:\n",
    "![](./images/other_encoding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "\n",
    "### Label encoding\n",
    "\n",
    "Label encoding (Exercise):\n",
    "\n",
    "Let's work on categorical variables encoding. You will again work with a subsample from the House Prices Kaggle competition.\n",
    "\n",
    "Your objective is to encode categorical features \"RoofStyle\" and \"CentralAir\" using label encoding. The train and test DataFrames are already available in your workspace.\n",
    "\n",
    "Instructions:\n",
    "- Concatenate train and test DataFrames into a single DataFrame houses.\n",
    "- Create a LabelEncoder object without arguments and assign it to le.\n",
    "- Create new label-encoded features for \"RoofStyle\" and \"CentralAir\" using the same le object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./datasets/house_prices_train.csv')\n",
    "test = pd.read_csv('./datasets/house_prices_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofStyle_enc</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>CentralAir_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gable</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gable</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gable</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gable</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gable</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RoofStyle  RoofStyle_enc CentralAir  CentralAir_enc\n",
       "0     Gable              1          Y               1\n",
       "1     Gable              1          Y               1\n",
       "2     Gable              1          Y               1\n",
       "3     Gable              1          Y               1\n",
       "4     Gable              1          Y               1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenate train and test together\n",
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Create new features\n",
    "houses['RoofStyle_enc'] = le.fit_transform(houses['RoofStyle'])\n",
    "houses['CentralAir_enc'] = le.fit_transform(houses['CentralAir'])\n",
    "\n",
    "# Look at new features\n",
    "display(houses[['RoofStyle', 'RoofStyle_enc', 'CentralAir', 'CentralAir_enc']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right! You can see that categorical variables have been label encoded. However, as you already know, label encoder is not always a good choice for categorical variables. Let's go further and apply One-Hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### One-Hot encoding\n",
    "\n",
    "One-Hot encoding (Exercise)\n",
    "The problem with label encoding is that it implicitly assumes that there is a ranking dependency between the categories. So, let's change the encoding method for the features \"RoofStyle\" and \"CentralAir\" to one-hot encoding. Again, the train and test DataFrames from House Prices Kaggle competition are already available in your workspace.\n",
    "\n",
    "Recall that if you're dealing with binary features (categorical features with only two categories) it is suggested to apply label encoder only.\n",
    "\n",
    "Your goal is to determine which of the mentioned features is not binary, and to apply one-hot encoding only to this one.\n",
    "\n",
    "Instructions:\n",
    "- Determine the distribution of \"RoofStyle\" and \"CentralAir\" features using pandas' value_counts() method.\n",
    "- For the categorical feature \"RoofStyle\" let's use the one-hot encoder. Firstly, create one-hot encoded features using the get_dummies() method. Then they are concatenated to the initial houses DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gable      2310\n",
      "Hip         551\n",
      "Gambrel      22\n",
      "Flat         20\n",
      "Mansard      11\n",
      "Shed          5\n",
      "Name: RoofStyle, dtype: int64 \n",
      "\n",
      "Y    2723\n",
      "N     196\n",
      "Name: CentralAir, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Concatenate train and test together\n",
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Look at feature distributions\n",
    "print(houses['RoofStyle'].value_counts(), '\\n')\n",
    "print(houses['CentralAir'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofStyle_Flat</th>\n",
       "      <th>RoofStyle_Gable</th>\n",
       "      <th>RoofStyle_Gambrel</th>\n",
       "      <th>RoofStyle_Hip</th>\n",
       "      <th>RoofStyle_Mansard</th>\n",
       "      <th>RoofStyle_Shed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gable</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gable</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gable</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RoofStyle  RoofStyle_Flat  RoofStyle_Gable  RoofStyle_Gambrel  RoofStyle_Hip  RoofStyle_Mansard  RoofStyle_Shed\n",
       "0     Gable               0                1                  0              0                  0               0\n",
       "1     Gable               0                1                  0              0                  0               0\n",
       "2     Gable               0                1                  0              0                  0               0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Concatenate train and test together\n",
    "houses = pd.concat([train, test])\n",
    "\n",
    "# Label encode binary 'CentralAir' feature\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "houses['CentralAir_enc'] = le.fit_transform(houses['CentralAir'])\n",
    "\n",
    "# Create One-Hot encoded features\n",
    "ohe = pd.get_dummies(houses['RoofStyle'], prefix='RoofStyle')\n",
    "\n",
    "# Concatenate OHE features to houses\n",
    "houses = pd.concat([houses, ohe], axis=1)\n",
    "\n",
    "# Look at OHE features\n",
    "display(houses[[col for col in houses.columns if 'RoofStyle' in col]].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "Which of the features is binary?\n",
    "----> \"CentralAir\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoding\n",
    "\n",
    "![](./images/target_encode.png)\n",
    "\n",
    "\n",
    "High cardinality categorical features:\n",
    "\n",
    "![](./images/high_cardinality_problem.png)\n",
    "\n",
    "\n",
    "![](./images/mean_target_encoding1.png)\n",
    "\n",
    "\n",
    "![](./images/mean_target_encoding2.png)\n",
    "\n",
    "\n",
    "![](./images/mean_target_encoding3.png)\n",
    "\n",
    "\n",
    "![](./images/mean_target_encoding4.png)\n",
    "\n",
    "\n",
    "Some extra tips:\n",
    "- Smoothing\n",
    "\n",
    "![](./images/mean_target_encoding5.png)\n",
    "\n",
    "- Global mean for new category: (C: 2/5 = 0.4)\n",
    "\n",
    "![](./images/mean_target_encoding6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean target encoding\n",
    "\n",
    "Mean target encoding (Exercise):\n",
    "\n",
    "First of all, you will create a function that implements mean target encoding. Remember that you need to develop the two following steps:\n",
    "\n",
    "Calculate the mean on the train, apply to the test\n",
    "Split train into K folds. Calculate the out-of-fold mean for each fold, apply to this particular fold\n",
    "Each of these steps will be implemented in a separate function: test_mean_target_encoding() and train_mean_target_encoding(), respectively.\n",
    "\n",
    "The final function mean_target_encoding() takes as arguments: the train and test DataFrames, the name of the categorical column to be encoded, the name of the target column and a smoothing parameter alpha. It returns two values: a new feature for train and test DataFrames, respectively.\n",
    "\n",
    "Instructions:\n",
    "- You need to add smoothing to avoid overfitting. So, add  parameter to the denominator in train_statistics calculations.\n",
    "- You need to treat new categories in the test data. So, pass a global mean as an argument to the fillna() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "    # Calculate global mean on the train data\n",
    "    global_mean = train[target].mean()\n",
    "    \n",
    "    # Group by the categorical feature and calculate its properties\n",
    "    train_groups = train.groupby(categorical)\n",
    "    category_sum = train_groups[target].sum()\n",
    "    category_size = train_groups.size()\n",
    "    \n",
    "    # Calculate smoothed mean target statistics\n",
    "    train_statistics = (category_sum + global_mean * alpha) / (category_size + alpha)\n",
    "    \n",
    "    # Apply statistics to the test data and fill new categories\n",
    "    test_feature = test[categorical].map(train_statistics).fillna(global_mean)\n",
    "    return test_feature.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To calculate the train mean encoded feature you need to use out-of-fold statistics, splitting train into several folds. Specify the train and test indices for each validation split to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mean_target_encoding(train, target, categorical, alpha=5):\n",
    "    # Create 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "    train_feature = pd.Series(index=train.index, dtype='float')\n",
    "    \n",
    "    # For each folds split\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "      \n",
    "        # Calculate out-of-fold statistics and apply to cv_test\n",
    "        cv_test_feature = test_mean_target_encoding(cv_train, cv_test, target, categorical, alpha)\n",
    "        \n",
    "        # Save new feature for this particular fold\n",
    "        train_feature.iloc[test_index] = cv_test_feature       \n",
    "    return train_feature.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, you just calculate train and test target mean encoded features and return them from the function. So, return train_feature and test_feature obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "  \n",
    "    # Get the train feature\n",
    "    train_feature = train_mean_target_encoding(train, target, categorical, alpha)\n",
    "  \n",
    "    # Get the test feature\n",
    "    test_feature = test_mean_target_encoding(train, test, target, categorical, alpha)\n",
    "    \n",
    "    # Return new features to add to the model\n",
    "    return train_feature, test_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are equipped with a function that performs mean target encoding of any categorical feature. Move on to learn how to implement mean target encoding for the K-fold cross-validation using the mean_target_encoding() function you've just built!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "### K-fold cross-validation\n",
    "\n",
    "K-fold cross-validation (Exercise)\n",
    "\n",
    "You will work with a binary classification problem on a subsample from Kaggle playground competition. The objective of this competition is to predict whether a famous basketball player Kobe Bryant scored a basket or missed a particular shot.\n",
    "\n",
    "Train data is available in your workspace as bryant_shots DataFrame. It contains data on 10,000 shots with its properties and a target variable \"shot\\_made\\_flag\" -- whether shot was scored or not.\n",
    "\n",
    "One of the features in the data is \"game_id\" -- a particular game where the shot was made. There are 541 distinct games. So, you deal with a **high-cardinality** categorical feature. Let's encode it using **a target mean**!\n",
    "\n",
    "Suppose you're using 5-fold cross-validation and want to evaluate a mean target encoded feature on the local validation.\n",
    "\n",
    "Instructions:\n",
    "- To achieve this, you need to repeat encoding procedure for the \"game_id\" categorical feature inside each folds split separately. Your goal is to specify all the missing parameters for the mean_target_encoding() function call inside each folds split.\n",
    "- Recall that the train and test parameters expect the train and test DataFrames.\n",
    "- While the target and categorical parameters expect names of the target variable and categorical feature to be encoded.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shot_id</th>\n",
       "      <th>game_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>minutes_remaining</th>\n",
       "      <th>playoffs</th>\n",
       "      <th>season</th>\n",
       "      <th>shot_distance</th>\n",
       "      <th>shot_type</th>\n",
       "      <th>shot_made_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>20000012</td>\n",
       "      <td>34.0443</td>\n",
       "      <td>-118.4268</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>15</td>\n",
       "      <td>2PT Field Goal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>20000012</td>\n",
       "      <td>33.9093</td>\n",
       "      <td>-118.3708</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>16</td>\n",
       "      <td>2PT Field Goal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>20000012</td>\n",
       "      <td>33.8693</td>\n",
       "      <td>-118.1318</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>22</td>\n",
       "      <td>2PT Field Goal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>20000012</td>\n",
       "      <td>34.0443</td>\n",
       "      <td>-118.2698</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>0</td>\n",
       "      <td>2PT Field Goal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>20000012</td>\n",
       "      <td>34.0553</td>\n",
       "      <td>-118.4148</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>14</td>\n",
       "      <td>2PT Field Goal</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shot_id   game_id      lat       lon  minutes_remaining  playoffs   season  shot_distance       shot_type  shot_made_flag\n",
       "0        2  20000012  34.0443 -118.4268                 10         0  2000-01             15  2PT Field Goal             0.0\n",
       "1        3  20000012  33.9093 -118.3708                  7         0  2000-01             16  2PT Field Goal             1.0\n",
       "2        4  20000012  33.8693 -118.1318                  6         0  2000-01             22  2PT Field Goal             0.0\n",
       "3        5  20000012  34.0443 -118.2698                  6         0  2000-01              0  2PT Field Goal             1.0\n",
       "4        6  20000012  34.0553 -118.4148                  9         0  2000-01             14  2PT Field Goal             0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shot_id</th>\n",
       "      <th>game_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>minutes_remaining</th>\n",
       "      <th>playoffs</th>\n",
       "      <th>shot_distance</th>\n",
       "      <th>shot_made_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5957.429200</td>\n",
       "      <td>2.032651e+07</td>\n",
       "      <td>33.957233</td>\n",
       "      <td>-118.260528</td>\n",
       "      <td>4.969800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.25660</td>\n",
       "      <td>0.450800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3449.286328</td>\n",
       "      <td>2.137839e+05</td>\n",
       "      <td>0.088840</td>\n",
       "      <td>0.111615</td>\n",
       "      <td>3.530911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.54781</td>\n",
       "      <td>0.497598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000001e+07</td>\n",
       "      <td>33.303300</td>\n",
       "      <td>-118.514800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2953.750000</td>\n",
       "      <td>2.010106e+07</td>\n",
       "      <td>33.886300</td>\n",
       "      <td>-118.335800</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5957.500000</td>\n",
       "      <td>2.030103e+07</td>\n",
       "      <td>33.977300</td>\n",
       "      <td>-118.269800</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8935.250000</td>\n",
       "      <td>2.050081e+07</td>\n",
       "      <td>34.044300</td>\n",
       "      <td>-118.166800</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11934.000000</td>\n",
       "      <td>2.070036e+07</td>\n",
       "      <td>34.088300</td>\n",
       "      <td>-118.021800</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            shot_id       game_id           lat           lon  minutes_remaining  playoffs  shot_distance  shot_made_flag\n",
       "count  10000.000000  1.000000e+04  10000.000000  10000.000000       10000.000000   10000.0    10000.00000    10000.000000\n",
       "mean    5957.429200  2.032651e+07     33.957233   -118.260528           4.969800       0.0       13.25660        0.450800\n",
       "std     3449.286328  2.137839e+05      0.088840      0.111615           3.530911       0.0        9.54781        0.497598\n",
       "min        2.000000  2.000001e+07     33.303300   -118.514800           0.000000       0.0        0.00000        0.000000\n",
       "25%     2953.750000  2.010106e+07     33.886300   -118.335800           2.000000       0.0        4.00000        0.000000\n",
       "50%     5957.500000  2.030103e+07     33.977300   -118.269800           5.000000       0.0       15.00000        0.000000\n",
       "75%     8935.250000  2.050081e+07     34.044300   -118.166800           8.000000       0.0       20.00000        1.000000\n",
       "max    11934.000000  2.070036e+07     34.088300   -118.021800          11.000000       0.0       74.00000        1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   shot_id            10000 non-null  int64  \n",
      " 1   game_id            10000 non-null  int64  \n",
      " 2   lat                10000 non-null  float64\n",
      " 3   lon                10000 non-null  float64\n",
      " 4   minutes_remaining  10000 non-null  int64  \n",
      " 5   playoffs           10000 non-null  int64  \n",
      " 6   season             10000 non-null  object \n",
      " 7   shot_distance      10000 non-null  int64  \n",
      " 8   shot_type          10000 non-null  object \n",
      " 9   shot_made_flag     10000 non-null  float64\n",
      "dtypes: float64(3), int64(5), object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541\n"
     ]
    }
   ],
   "source": [
    "bryant_shots = pd.read_csv('./datasets/bryant_shots.csv')\n",
    "\n",
    "display(bryant_shots.head())\n",
    "display(bryant_shots.describe())\n",
    "display(bryant_shots.info())\n",
    "print(len(bryant_shots.game_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>shot_made_flag</th>\n",
       "      <th>game_id_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6169</th>\n",
       "      <td>20401035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       game_id  shot_made_flag  game_id_enc\n",
       "6169  20401035             0.0     0.485855"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>shot_made_flag</th>\n",
       "      <th>game_id_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>20400158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       game_id  shot_made_flag  game_id_enc\n",
       "5423  20400158             0.0     0.327632"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>shot_made_flag</th>\n",
       "      <th>game_id_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>20400181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.589342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       game_id  shot_made_flag  game_id_enc\n",
       "5429  20400181             1.0     0.589342"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>shot_made_flag</th>\n",
       "      <th>game_id_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7871</th>\n",
       "      <td>20501026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.313008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       game_id  shot_made_flag  game_id_enc\n",
       "7871  20501026             1.0     0.313008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>shot_made_flag</th>\n",
       "      <th>game_id_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6887</th>\n",
       "      <td>20500372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.376618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       game_id  shot_made_flag  game_id_enc\n",
       "6887  20500372             1.0     0.376618"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "# For each folds split\n",
    "for train_index, test_index in kf.split(bryant_shots):\n",
    "    cv_train, cv_test = bryant_shots.iloc[train_index].copy(), bryant_shots.iloc[test_index].copy()\n",
    "\n",
    "    # Create mean target encoded feature\n",
    "    cv_train['game_id_enc'], cv_test['game_id_enc'] = mean_target_encoding(train=cv_train,\n",
    "                                                                           test=cv_test,\n",
    "                                                                           target='shot_made_flag',\n",
    "                                                                           categorical='game_id',\n",
    "                                                                           alpha=5)\n",
    "    # Look at the encoding\n",
    "    display(cv_train[['game_id', 'shot_made_flag', 'game_id_enc']].sample(n=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could see different game encodings for each validation split in the output. The main conclusion you should make: **while using local cross-validation, you need to repeat mean target encoding procedure inside each folds split separately**. Go on to try other problem types beyond binary classification!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Beyond binary classification\n",
    "\n",
    "Beyond binary classification (Exercise)\n",
    "\n",
    "Of course, binary classification is just a single special case. Target encoding could be applied to any target variable type:\n",
    "\n",
    "For binary classification usually mean target encoding is used\n",
    "For regression mean could be changed to median, quartiles, etc.\n",
    "For multi-class classification with N classes we create N features with target mean for each category in one vs. all fashion\n",
    "The mean_target_encoding() function you've created could be used for any target type specified above. Let's apply it for the regression problem on the example of House Prices Kaggle competition.\n",
    "\n",
    "Your goal is to encode a categorical feature \"RoofStyle\" using mean target encoding. The train and test DataFrames are already available in your workspace.\n",
    "\n",
    "Instructions:\n",
    "- Specify all the missing parameters for the mean_target_encoding() function call. Target variable name is \"SalePrice\". Set  hyperparameter to 10.\n",
    "- Recall that the train and test parameters expect the train and test DataFrames.\n",
    "- While the target and categorical parameters expect names of the target variable and feature to be encoded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofStyle_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gable</td>\n",
       "      <td>171565.947836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hip</td>\n",
       "      <td>217594.645131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Gambrel</td>\n",
       "      <td>164152.950424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Flat</td>\n",
       "      <td>188703.563431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Mansard</td>\n",
       "      <td>180775.938759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Shed</td>\n",
       "      <td>188267.663242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     RoofStyle  RoofStyle_enc\n",
       "0        Gable  171565.947836\n",
       "1          Hip  217594.645131\n",
       "98     Gambrel  164152.950424\n",
       "133       Flat  188703.563431\n",
       "362    Mansard  180775.938759\n",
       "1053      Shed  188267.663242"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./datasets/house_prices_train.csv')\n",
    "test = pd.read_csv('./datasets/house_prices_test.csv')\n",
    "\n",
    "# Create mean target encoded feature\n",
    "train['RoofStyle_enc'], test['RoofStyle_enc'] = mean_target_encoding(train=train,\n",
    "                                                                     test=test, \n",
    "                                                                     target='SalePrice',\n",
    "                                                                     categorical='RoofStyle',\n",
    "                                                                     alpha=10)\n",
    "# Look at the encoding\n",
    "test[['RoofStyle', 'RoofStyle_enc']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, you observe that houses with the **Hip roof are the most pricy**, while houses with the Gambrel roof are the cheapest. It's exactly the goal of target encoding: you've encoded categorical feature in such a manner that there is now a correlation between category values and target variable. We're done with categorical encoders. Now it's time to talk about the missing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "![](./images/missing_data.png)\n",
    "\n",
    "- Mean/median imputation\n",
    "\n",
    "![](./images/impute1.png)\n",
    "\n",
    "\n",
    "- Constant value imputation \n",
    "\n",
    "![](./images/impute2.png)\n",
    "\n",
    "\n",
    "- Most frequent category imputation\n",
    "\n",
    "![](./images/impute3.png)\n",
    "\n",
    "- New category imputation\n",
    "\n",
    "![](./images/impute4.png)\n",
    "\n",
    "\n",
    "### Find Missing Data\n",
    "\n",
    "![](./images/find_missing.png)\n",
    "\n",
    "![](./images/numerical_impute.png)\n",
    "\n",
    "![](./images/categorical_impute.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find missing data (Exercise):\n",
    "\n",
    "Let's impute missing data on a real Kaggle dataset. For this purpose, you will be using a data subsample from the Kaggle \"Two sigma connect: rental listing inquiries\" competition.\n",
    "\n",
    "Before proceeding with any imputing you need to know the number of missing values for each of the features. Moreover, if the feature has missing values, you should explore the type of this feature.\n",
    "\n",
    "Instructions:\n",
    "- Read the \"twosigma_train.csv\" file using pandas.\n",
    "- Find the number of missing values in each column.\n",
    "- Select the columns with the missing values and look at the head of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                 0\n",
      "bathrooms          0\n",
      "bedrooms           0\n",
      "building_id       13\n",
      "latitude           0\n",
      "longitude          0\n",
      "manager_id         0\n",
      "price             32\n",
      "interest_level     0\n",
      "dtype: int64\n",
      "                        building_id   price\n",
      "0  53a5b119ba8f7b61d4e010512e0dfc85  3000.0\n",
      "1  c5c8a357cba207596b04d1afd1e4f130  5465.0\n",
      "2  c3ba40552e2120b0acfc3cb5730bb2aa  2850.0\n",
      "3  28d9ad350afeaab8027513a3e52ac8d5  3275.0\n",
      "4                               NaN  3350.0\n"
     ]
    }
   ],
   "source": [
    "# Read DataFrame\n",
    "twosigma = pd.read_csv('./datasets/twosigma_rental_train_null.csv')\n",
    "# Find the number of missing values in each column\n",
    "print(twosigma.isnull().sum())\n",
    "\n",
    "# Look at the columns with the missing values\n",
    "print(twosigma[['building_id', 'price']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, you've found out that 'building_id' and 'price' columns have missing values. Looking at the head of the DataFrame, we may conclude that 'price' is a numerical feature, while 'building_id' is a categorical feature that is encoding buildings as hashes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Data\n",
    "\n",
    "\n",
    "Impute missing data (Exercise)\n",
    "\n",
    "You've found that \"price\" and \"building_id\" columns have missing values in the Rental Listing Inquiries dataset. So, before passing the data to the models you need to impute these values.\n",
    "\n",
    "Numerical feature \"price\" will be encoded with a mean value of non-missing prices.\n",
    "\n",
    "Imputing categorical feature \"building_id\" with the most frequent category is a bad idea, because it would mean that all the apartments with a missing \"building_id\" are located in the most popular building. The better idea is to impute it with a new category.\n",
    "\n",
    "The DataFrame rental_listings with competition data is read for you.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Create a SimpleImputer object with \"mean\" strategy.\n",
    "- Impute missing prices with the mean value.\n",
    "\n",
    "- Create an imputer with \"constant\" strategy. Use \"MISSING\" as fill_value.\n",
    "- Impute missing buildings with a constant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                0\n",
      "bathrooms         0\n",
      "bedrooms          0\n",
      "building_id       0\n",
      "latitude          0\n",
      "longitude         0\n",
      "manager_id        0\n",
      "price             0\n",
      "interest_level    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "rental_listings = twosigma.copy()\n",
    "\n",
    "# Create mean imputer\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Price imputation\n",
    "rental_listings[['price']] = mean_imputer.fit_transform(rental_listings[['price']])\n",
    "\n",
    "\n",
    "# Create constant imputer\n",
    "constant_imputer = SimpleImputer(strategy='constant', fill_value=\"MISSING\")\n",
    "\n",
    "# building_id imputation\n",
    "rental_listings[['building_id']] = constant_imputer.fit_transform(rental_listings[['building_id']])\n",
    "\n",
    "\n",
    "print(rental_listings.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now our data is ready to be passed to any Machine Learning model. Move on to the next chapter to build and improve your models!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('my_conda_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f080ef3f7e154a5496448b61eb994fbc79c03fae547c033702ffc1b7b2a346b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
